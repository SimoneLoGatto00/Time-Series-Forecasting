{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Time Series Forecasting \n",
        "\n",
        "This project tackles multi-step forecasting of univariate time series generated by different underlying processes. We build and train a GRU + Conv1D neural model to predict future trajectories, significantly outperforming simple baseline predictors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap3o8JayfgEM"
      },
      "source": [
        "## 1. Setup and imports\n",
        "\n",
        "We start by fixing the random seed for reproducibility and importing the main libraries:\n",
        "- `numpy`, `pandas`, `matplotlib`, `seaborn` for data handling and visualisation\n",
        "- `tensorflow.keras` for building and training the neural network\n",
        "- `sklearn` for train/validation/test splitting and preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR-w0eZ-ABIT"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06wPZJbADcv",
        "outputId": "6b650d5e-e11d-4bd9-9980-47c16f8479ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow / Keras and configure logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN6wKImkADfL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49TrZ82D-Fl"
      },
      "source": [
        "## 2. Load and preprocess the data\n",
        "\n",
        "We load:\n",
        "- `training_data.npy`: list of time series\n",
        "- `categories.npy`: class label for each time series (6 underlying processes)\n",
        "- `valid_periods.npy`: valid index ranges for each series\n",
        "\n",
        "We then:\n",
        "- restrict each series to its valid interval\n",
        "- filter out very short sequences\n",
        "- prepare a clean dataset for sequence building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdPmSVyIwF3n"
      },
      "outputs": [],
      "source": [
        "dataset = np.load('training_data.npy')\n",
        "label = np.load('categories.npy')\n",
        "valid = np.load('valid_periods.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn-Zea5-yZOK",
        "outputId": "330bbdbc-2eae-4dd0-8246-f77bc9dd66ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((48000,), (48000,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Contains the sliced rows\n",
        "valid_dataset = []\n",
        "\n",
        "for i,v in enumerate(valid):\n",
        "    start = v[0]\n",
        "    end = v[1]\n",
        "    valid_dataset.append(dataset[i][start:end+1])  # +1 to include the 'end' index\n",
        "\n",
        "# Convert the list of valid rows back to a NumPy array\n",
        "valid_dataset = np.array(valid_dataset)\n",
        "\n",
        "valid_dataset.shape, label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6bU1uPqqQiS"
      },
      "source": [
        "### 2.1 Filter out short time series\n",
        "\n",
        "We discard or truncate series that are too short for our chosen input window (`window = 200`) and forecasting horizon (`telescope`), in order to:\n",
        "\n",
        "- reduce the amount of padding,\n",
        "- avoid sequences with too little information,\n",
        "- keep the dataset as homogeneous as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCiIS97gv_mU",
        "outputId": "a0a3e70d-0399-4ba7-b64a-136804001e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A appears 5728 time(s)\n",
            "B appears 10987 time(s)\n",
            "C appears 10017 time(s)\n",
            "D appears 10016 time(s)\n",
            "E appears 10975 time(s)\n",
            "F appears 277 time(s)\n"
          ]
        }
      ],
      "source": [
        "# Get the unique values and their counts\n",
        "value_counts = {value: np.count_nonzero(label == value) for value in np.unique(label)}\n",
        "tmp_size = len(label)\n",
        "# Print the results\n",
        "for value, count in value_counts.items():\n",
        "    print(f\"{value} appears {count} time(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loqtrmnUD-zh"
      },
      "outputs": [],
      "source": [
        "limit = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiPQyAhSqWeo",
        "outputId": "f97e101b-e952-421f-d5e6-2196e55b7582"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((23057,), (23057,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reduced_valid_dataset = []\n",
        "reduced_labels = []\n",
        "for i,v in enumerate(valid_dataset):\n",
        "  if len(v) >= limit:# or label[i]=='B':\n",
        "    reduced_valid_dataset.append(v)\n",
        "    reduced_labels.append(label[i])\n",
        "valid_dataset = np.array(reduced_valid_dataset)\n",
        "label = np.array(reduced_labels)\n",
        "valid_dataset.shape, label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP_q8OeCtoQe",
        "outputId": "9f6b62b3-ccd0-46f9-b623-fa982c4866ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A appears 4088 time(s)\n",
            "B appears 3671 time(s)\n",
            "C appears 5282 time(s)\n",
            "D appears 5633 time(s)\n",
            "E appears 4263 time(s)\n",
            "F appears 120 time(s)\n"
          ]
        }
      ],
      "source": [
        "# Get the unique values and their counts\n",
        "value_counts = {value: np.count_nonzero(label == value) for value in np.unique(label)}\n",
        "tmp_size_2 = len(label)\n",
        "# Print the results\n",
        "for value, count in value_counts.items():\n",
        "    print(f\"{value} appears {count} time(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxKPuP7_pdSC"
      },
      "source": [
        "## 3. Build inputâ€“output sequences\n",
        "\n",
        "We convert each variable-length time series into multiple fixed-length sequences:\n",
        "\n",
        "- each input window has length `window` (e.g. 200 samples),\n",
        "- each target vector contains the next `telescope` samples (e.g. 18 steps ahead),\n",
        "- we slide a window with stride `stride` and collect all valid (input, output) pairs.\n",
        "\n",
        "This function returns:\n",
        "- `X`: array of input windows,\n",
        "- `y`: array of corresponding future trajectories,\n",
        "- `cat`: class label for each window.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tViv24Bvpfl0"
      },
      "outputs": [],
      "source": [
        "window = 200\n",
        "stride = 20\n",
        "telescope = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTDehdRvqvCi"
      },
      "outputs": [],
      "source": [
        "def build_sequences(valid_dataset = valid_dataset, categories = label, window=window, stride=stride, telescope=telescope):\n",
        "assert window % stride == 0, \"Window length should be a multiple of stride.\"\n",
        "\n",
        "    X = []              # input windows (seen part)\n",
        "    y = []              # target sequences (unseen part)\n",
        "    new_categories = [] # category per window\n",
        "\n",
        "    for i, series in enumerate(valid_dataset):\n",
        "        temp = np.array(series)\n",
        "\n",
        "        # Ignore the tail that would be used as target\n",
        "        effective_length = len(temp) - telescope\n",
        "\n",
        "        # If the effective length is below the window, pad up to `window`\n",
        "        if effective_length < window:\n",
        "            pad_len = window - effective_length\n",
        "            temp = np.concatenate([temp, np.repeat(temp[-1], pad_len)])\n",
        "            effective_length = len(temp) - telescope\n",
        "\n",
        "        # Ensure the remaining length is compatible with the chosen stride\n",
        "        assert effective_length % stride == 0\n",
        "\n",
        "        # Slide the window and build (input, output) pairs\n",
        "        for idx in np.arange(0, len(temp) - window - telescope + 1, stride):\n",
        "            X.append(temp[idx : idx + window])\n",
        "            y.append(temp[idx + window : idx + window + telescope])\n",
        "            new_categories.append(categories[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    new_categories = np.array(new_categories)\n",
        "\n",
        "    return X, y, new_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUA8S0KZqEIy",
        "outputId": "5ca0840d-00f7-4284-85eb-d2bec77e5c1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((126635, 200), (126635, 18), (126635,))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y, cat = build_sequences()\n",
        "X.shape, y.shape, cat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkvT29Q0jBpt"
      },
      "source": [
        "## 4. Train / validation / test split\n",
        "\n",
        "We split the data into:\n",
        "- train\n",
        "- validation\n",
        "- test\n",
        "\n",
        "using stratified splitting on the class label to preserve the class distribution across all sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJjrtgiwjBpt"
      },
      "outputs": [],
      "source": [
        "# Dataframes with a time series per each row\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJrKGmQQjBpt"
      },
      "outputs": [],
      "source": [
        "# Add category column\n",
        "X['category'] = cat\n",
        "y['category'] = cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06_REWWDjBpu"
      },
      "outputs": [],
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size = 0.1,\n",
        "    stratify = X['category'],\n",
        "    random_state = seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1RFd6NxrkXj",
        "outputId": "ba11815c-cc70-4d75-9fde-f20c9e12755d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((101307, 201), (12664, 201), (101307, 19), (12664, 19))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val,\n",
        "    y_train_val,\n",
        "    test_size = len(X_test),\n",
        "    stratify = X_train_val['category'],\n",
        "    random_state = seed,\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev_hx62yjBpv"
      },
      "outputs": [],
      "source": [
        "# Deleting the column \"category\"\n",
        "X_test_categories = X_test['category'].to_numpy()\n",
        "X_train = X_train.drop('category', axis=1)\n",
        "X_val = X_val.drop('category', axis=1)\n",
        "X_test = X_test.drop('category', axis=1)\n",
        "\n",
        "y_train = y_train.drop('category', axis=1)\n",
        "y_val = y_val.drop('category', axis=1)\n",
        "y_test = y_test.drop('category', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "256MPRWbjBpv"
      },
      "outputs": [],
      "source": [
        "# Expanding 1 dimension\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "y_test = np.expand_dims(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdCgbYBMjBpw",
        "outputId": "3e34a091-0458-4dc4-cfa5-4505a87d3797"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((101307, 200, 1),\n",
              " (101307, 18, 1),\n",
              " (12664, 200, 1),\n",
              " (12664, 18, 1),\n",
              " (12664, 200, 1),\n",
              " (12664, 18, 1))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWoSxRuc9-vi"
      },
      "source": [
        "## 5. Model definition and training\n",
        "\n",
        "We define a GRU + Conv1D architecture and train it using:\n",
        "- Mean Squared Error (MSE) loss\n",
        "- Adam optimizer\n",
        "- EarlyStopping and ReduceLROnPlateau on the validation loss\n",
        "\n",
        "We also save the best model weights using ModelCheckpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_dB1Ssz-CYy"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train_val.shape[1:]\n",
        "output_shape = y_train_val.shape[1:]\n",
        "batch_size = 128\n",
        "epochs = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r38MQcU4phAB"
      },
      "outputs": [],
      "source": [
        "def build_CONV_GRU_DENSE_model(input_shape, output_shape):\n",
        "    assert input_shape[0] >= output_shape[0], \\\n",
        "        \"For this exercise we want input time steps to be >= output time steps.\"\n",
        "\n",
        "    inputs = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # Bidirectional GRU to capture temporal dependencies\n",
        "    x = tfkl.Bidirectional(\n",
        "        tfkl.GRU(32, return_sequences=True, name='gru'),\n",
        "        name='bidirectional_gru'\n",
        "    )(inputs)\n",
        "\n",
        "    # 1D convolution to extract local patterns in the hidden states\n",
        "    x = tfkl.Conv1D(64, 3, padding='same', activation='gelu', name='conv1')(x)\n",
        "\n",
        "    # Global pooling + dense projection to the forecasting horizon\n",
        "    x = tfkl.GlobalAveragePooling1D()(x)\n",
        "    x = tfkl.Flatten()(x)\n",
        "    outputs = tfkl.Dense(output_shape[0], activation='relu')(x)\n",
        "    outputs = tfkl.Reshape(output_shape)(outputs)\n",
        "\n",
        "    model = tfk.Model(inputs=inputs, outputs=outputs, name='CONV_GRU_DENSE_model')\n",
        "    model.compile(\n",
        "        loss=tfk.losses.MeanSquaredError(),\n",
        "        optimizer=tfk.optimizers.Adam()\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MhAmgJKZCGIl",
        "outputId": "d55266b1-f555-4dc9-e389-1f948d046104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"CONV_GRU_DENSE_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 200, 1)]          0         \n",
            "                                                                 \n",
            " bidirectional_gru (Bidirec  (None, 200, 64)           6720      \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " conv2 (Conv1D)              (None, 200, 64)           12352     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 64)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 18)                1170      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 18, 1)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20242 (79.07 KB)\n",
            "Trainable params: 20242 (79.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAALhCAIAAABXP632AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVwT1944/jOQkEliwiKrKFtYFMVal1ZQH7T2ZavcooAKrbYP2AVtbcQFERRURFzwAo8ItSrlvi70usIFi1L7Qi9aruhjq3yhqIiIUrDKvoZIgPn9cZ47vzQMIQlLAD/vv8iZyZkz55x8mDNzZoagKAoBAADoRUfbBQAAgBEK4iMAADCD+AgAAMwgPgIAADOWtgugnoKCgtjYWG2XAgCgCVdX1y1btmi7FGoYZcePv//++4ULF7RditGnqqpqDNfbhQsXqqqqtF0K0I9bt24VFBRouxTqGWXHj9j58+e1XYRR5ty5c76+vmO13giC2Lx58+rVq7VdEKDMqlWrtF0EtY2y40cAABg2EB8BAIAZxEcAAGAG8REAAJhBfAQAAGZjMz5evnxZX1//hx9+0G4xjhw5YmpqShDE8ePHtVsSzYyQahwU69evJ/5j7dq18otyc3NDQ0PT09Pt7OzwCh9//LH8CkuWLBEIBLq6ulOnTr179+5wFjsyMtLZ2VkoFHI4HHt7++3bt7e1tdFL8/Pz582bx+PxLCwsQkJCXr16pcqifvX09MTFxbm5udEpFy9ePHToUHd3N52SmZlJ16exsfHA9nLkGpvxcYQ8lGjbtm03b97Udik0N0KqcbAYGRnl5OSUlpYmJyfTibt37z569GhYWJiPj8+TJ09EItH48ePT0tIuXbpEr/PTTz+dP3/+gw8+KCkpmTlz5nCW+dq1axs3bnz69GldXV10dHR8fDw9S6akpGTJkiWLFy+ura3NyMj47rvvNmzY0O+ifpWVlf3Xf/3Xli1bJBIJnejp6UmS5OLFi5uamnDK8uXLq6qqbty4sWzZssHb3ZGHGlXOnj07EsoskUhcXV1VWbOsrAwh9M033wx1kZQbIfWmQPVqVA4hdPbsWeXrBAYGWlpaKiQeOHDA0dGxo6ODThGJRN9//72Ojo6lpWVTUxOdnpOTs3z58oEXVV0eHh5dXV30RzzHs7KykqIoX19fW1vbnp4evCgmJoYgiAcPHihfpFxhYaG3t3daWtqMGTPeeOMNhaVisdjV1VUmk8knbtq0afz48arsy8qVK1euXKnKmiPH2Dx+HGrJyck1NTXaLsWop91qfPz4cXh4+N69e0mSlE93c3MLCgqqrq7etm2btspGy87O1tXVpT/ikaxEIunq6rp06ZK7uztBEHjR0qVLKYrKyspSsqjfzb3xxhvp6elr1qzhcDi9l+7Zs6ewsDA+Pn4QdmyUGIPxMT8/38rKiiCIY8eOIYSSkpL4fD6Px8vKylq6dKlQKJw4ceLp06cRQkePHiVJ0tTUdP369RYWFiRJurm53b59GyEkFov19PTMzc1xnl999RWfzycIoq6uLigoaOvWreXl5QRB2Nvbq1W2n3/+2dnZWV9fnyRJFxeXK1euIIQ+++wzfB5HJBLdu3cPIRQQEMDj8fT19S9evNjd3R0REWFlZcXlcqdPn46PBA8fPszj8QQCQU1NzdatWy0tLUtLSwe1FrVQjT/++KNQKNy/f//g7khfjh49SlGUp6dn70VRUVGOjo6nTp3Kzc3tvZSiqNjY2ClTpnA4HENDwxUrVjx8+BAprSKEEGM7qqu6uprL5dra2j558qStrc3KyopeJBKJEEJFRUVKFmmwRXmGhobu7u7x8fHU2DrxooxWj17VpuI48ffff0cIJSQk4I87d+5ECF29erW5ubmmpmbBggV8Pr+zs5OiqMDAQD6ff//+falUWlJSMmfOHIFAgMcva9asMTMzo/OMiYlBCNXW1lIU5ePjIxKJVCmwwvj6/Pnze/bsaWhoqK+vnzt3Lj0w8fHx0dXVra6upr/40UcfXbx4kaKobdu2cTicCxcuNDY2hoWF6ejo3Llzh96pTZs2JSQkeHt7Kx89aTa+HuZqzM7OFggEkZGR6pYTaTS+trOzc3Z2VlhNJBJVVFRQFHXz5k0dHR0bG5u2tjbqz+PriIgIPT291NTUpqamoqKimTNnGhsbv3jxQnkV9dWOqmtvbxcIBGKxmKKo69evI4RiYmLkV+ByuYsXL1aySPVtvf32273H1xRFhYaGIoTu3btHp8D4eoxwc3MTCoUmJiZ+fn7t7e2VlZU4ncVi4WMBZ2fnpKSk1tbWlJSUISrDypUrd+/ebWhoaGRk5OnpWV9fX1tbixDasGFDd3c3vd2WlpY7d+4sW7ZMKpUmJSV5eXn5+PgYGBjs2rWLzWbLF+/gwYMbN25MT0+fPHnyEJVZwdBVo4eHR0tLS3h4+BCUWlF7e3tFRQU+sGLk6uq6efPmp0+f7tixQz69o6MjNjbW29t77dq1+vr6Li4ux48fr6urO3HiBL1O7yrqtx1VER0dbWFhERUVhRDC16Plh94IITab3dHRoWSRWptj5ODggBAqLi4eeFajwmsUH2l6enoIIZlM1nvR7NmzeTweHi4NNTabjRDCcybeeecdR0fH7777jqIohNCZM2f8/Px0dXVLS0slEsm0adPwV7hcrrm5+fAUr18jpBo1U1NTQ1EUj8dTsk5UVJSTk1NiYmJ+fj6dWFJS0tbWNnv2bDplzpw5enp6+HyCArqKBt6OGRkZ586du3LlikAgQAjhc6ZdXV3y63R2dnK5XCWLVN9cX3CNvXz5cuBZjQqvY3xUjsPh4GO6oXDp0qWFCxeamJhwOJzt27fT6QRBrF+//smTJ1evXkUI/f3vf//0008RQu3t7QihXbt20XPNnj17Jj/xYsQa0mocOKlUihBivApBI0kyJSWFIIh169bRB194gsu4cePk1zQwMGhtbVWS1QDb8cyZMwcPHszLy7OxscEp+JRuS0sLvY5EIpFKpRYWFkoWqbg5JXCQxbX3OoD4+CcymaypqWnixIlDkXllZaWXl5e5ufnt27ebm5sPHTokv9Tf358kyVOnTpWWlgqFQmtra4SQiYkJQiguLk7+nMjIf4jekFbjoMC/c/kJz4zw81zLysr27duHUwwMDBBCCtGw350dSDsmJCSkpaVdu3ZtwoQJdKKtra1AIHj27Bmd8vjxY4TQ9OnTlSxSZXPKdXZ2ov/U3utgVD7/cejk5eVRFDV37lyEEIvFYhw8aqy4uFgmk3355Zd2dnYIIXr6BWZoaOjr63vmzBmBQPD555/jxEmTJpEkWVhYOIjFGAZDWo2DAt/X1Nzc3O+a+/bty87OvnfvHr4iPG3atHHjxv3yyy/0Crdv3+7s7Jw1a5aSTDRrR4qiduzY0djYmJmZyWL96afKYrGWLVt248aNnp4eHR0dhFBOTg5BEJ6enkoWqbV1RrjGzMzMBp7VqADHj6inp6exsbGrq6uoqCgoKMjKysrf3x8hZG9v39DQkJmZKZPJamtr5f8hGxkZPX/+/OnTp62trar/+PEPLDc3VyqVlpWV9T5jtWHDhlevXmVnZ3/wwQc4hSTJgICA06dPJyUltbS0dHd3V1VV/fHHHwPf60E38GrMyckZtvk9PB7Pzs5OlaeO41E2fbmDJMmtW7dmZGSkpaW1tLQUFxdv2LDBwsIiMDBQeSZ9taOfn5+ZmRnjbYv3798/fPjwyZMn2Ww2IefIkSMIofDw8JcvX+7evbu9vb2goCAmJsbf39/JyUn5IiWbUwWuMRcXF82+PvoM25XyQaHKPJWEhAR8CobH43l6eiYmJuKTyg4ODuXl5SdOnBAKhQgha2vrR48eBQYGstlsS0tLFoslFApXrFhRXl6O86mvr1+0aBFJkra2tl9//XVwcDBCyN7evrKy8u7du9bW1lwud/78+XhiB6O//vWv+D8tn8/39vamKCokJMTIyMjAwGDVqlV4XqFIJMLzYLA333wzNDRUPpNXr16FhIRYWVmxWCwTExMfH5+SkpJDhw7hMc6kSZNSU1MHpd60Xo2XL18WCARRUVFqlZPSdH6PWCxms9kSiQR/zMjIwJezjY2NN27cqPD14OBgen5PT09PTEyMg4MDm802NDT08vIqLS2lKEp5FTG2I0VRXl5eCKGIiIjeZe7rMjE9d+f69etvvfUWh8OxsLAIDg6WSqX0d/tapGRzFEUVFBTMmzePPlNpbm7u5uZ2/fp1egUPDw9LS0v6zhxqrM/vGYPxUS2BgYFGRkaDmOEALVu27MmTJ4Oe7VDfX6jdatQsPpaVlbFYLFX+uwyp7u7uBQsWJCcnj/zN1dXVkSR55MgR+cSxHR9hfN3/SfqhRo/Qi4qK8HGWdsujGa1XY786OjquXLlSVlaGLzLY29tHRkZGRkbKPxFnmHV3d2dmZra2tvr5+Y38ze3Zs2fGjBlisRghRFHU8+fP8/Pz8cWfsQri44A8fPiQ6JuKvTAkJKSsrOzRo0cBAQH0dVIw6BoaGt5//31HR8d169bhlNDQ0FWrVvn5+alyoWYo5OXlpaen5+TkKJ+JORI2FxsbW1hYePnyZTxvNysry9LScsGCBfIPOhqDtH0Aq57BHSeGhobiGbw2Njbnz58frGzVtXPnTh0dnUmTJuEbCofCkI6vtV6NSIXxtRJXrlwJCQkZxPKMPZmZmdHR0fJPEtLAaBxfE9SoutUcv6d0dJV5JBjb9UYQxNmzZ+H9riMcfnLl6HrJMIyvAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIDZqHw+hcKTHYCKxnC9+fr6+vr6arsUoB8rV67UdhHUMyrjo2bv7nidFRQUxMfHj9V68/X1DQoKcnV11XZBgDJxcXHaLoLaRmV8hJluGoiPjx+r9ebr6+vq6jpW927MGF0zHzE4/wgAAMwgPgIAADOIjwAAwAziIwAAMIP4CAAAzMZmfLx169aUKVN0dHQIgjAzM8OvVB9S6enpdnZ2+LGP5ubma9euHeotArWsX7+efi6nQuvk5uaGhobKt+DHH38sv8KSJUsEAoGuru7UqVM1fnOLZiIjI52dnYVCIYfDsbe33759u/zTfPPz8+fNm8fj8SwsLEJCQl69eqXKon719PTExcW5ubnRKRcvXjx06JD8I5AzMzPp+jQ2Nh7YXo5gWn6+mprUeo7he++9hxBqbGwc0iLJE4lE+vr6w7Y51Q31+xW0C6n2fgUjI6OcnJzS0lL597RERER88MEHLS0t+KNIJBo/fjxCKDs7W/7rOTk59PtnhpO7u3tiYmJ9fX1LS8vZs2fZbPb777+PF/32229cLjc8PLytre3mzZvGxsYBAQH9LurXo0eP5s2bhxB644035NPj4+Pd3d3pX1NPT09VVdWNGzeWLVs2ht+vMMp+MyMqPkokEldXV/mU1zM+9q6HYc5Exfio8P4ZiqIOHDjg6OjY0dFBp4hEou+//15HR8fS0rKpqYlO11Z89PDwkH8qLZ7jiV/o5uvra2trS78qKyYmhiCIBw8eKF+kXGFhobe3d1pa2owZMxTiI0VRYrHY1dVVJpPJJ8L7ZwCz5OTkmpoabZdC+walHoa/Mh8/fhweHr53716SJOXT3dzcgoKCqqurt23bNpzlYZSdnU2/WhYhhEeyEomkq6vr0qVL7u7u9D2jS5cupSgqKytLyaJ+N/fGG2+kp6evWbOGw+H0Xrpnz57CwsL4+PhB2LFR4nWJj0lJSXw+n8fjZWVlLV26VCgUTpw48fTp0wiho0ePkiRpamq6fv16CwsLkiTd3Nzwy6nFYrGenh5+zSlC6KuvvuLz+QRB1NXVBQUFbd26tby8nCAIe3t7Vcrw888/Ozs76+vrkyTp4uJy5coVhNBnn32GT+KIRKJ79+4hhAICAng8nr6+/sWLF7u7uyMiIqysrLhc7vTp0/Fh4OHDh3k8nkAgqKmp2bp1q6WlZWlp6aDUEkVRsbGxU6ZM4XA4hoaGK1asePjwoVr1MFiV+eOPPw71u7CPHj1KUZSnp2fvRVFRUY6OjqdOncrNze29tK9aUtLHEEKMTamu6upqLpdra2v75MmTtrY2/EZ1DL+ctqioSMkiDbYoz9DQ0N3dPT4+nhqjD6JnoM2DV/UNZHy9c+dOhNDVq1ebm5tramoWLFjA5/M7OzspigoMDOTz+ffv35dKpSUlJXPmzBEIBHgUs2bNGjMzMzrPmJgYhFBtbS1FUT4+PiKRSH6LysfX58+f37NnT0NDQ319/dy5c+lRiY+Pj66ubnV1Nb3mRx99hN9Fs23bNg6Hc+HChcbGxrCwMB0dnTt37tD7smnTpoSEBG9v736HTirWW0REhJ6eXmpqalNTU1FR0cyZM42NjfELvlWvh0GpzOzsbIFAEBkZ2W+ZKU3H13Z2ds7OzgqriUSiiooKiqJu3rypo6NjY2PT1tZG/Xl8raSWlPSxvppSde3t7QKBQCwWUxR1/fp1JPcibIzL5S5evFjJItW39fbbb/ceX1MUFRoaihC6d+8enQLj6zHFzc1NKBSamJj4+fm1t7dXVlbidBaLhY8InJ2dk5KSWltbU1JSBnfTK1eu3L17t6GhoZGRkaenZ319fW1tLUJow4YN3d3d9OZaWlru3LmzbNkyqVSalJTk5eXl4+NjYGCwa9cuNpstX6qDBw9u3LgxPT198uTJAy9eR0dHbGyst7f32rVr9fX1XVxcjh8/XldXd+LECXWzGnhlenh4tLS0hIeHq7tpFbW3t1dUVOADK0aurq6bN29++vTpjh075NNVqaXefazfplRFdHS0hYUFnoyBr0fLD70RQmw2u6OjQ8kitTbHyMHBASFUXFw88KxGhdcuPtLwK/fod0/Lmz17No/Hw4OmIYJfkoknTLzzzjuOjo7fffcdRVEIoTNnzvj5+enq6paWlkokkmnTpuGvcLlcc3PzoStVSUlJW1vb7Nmz6ZQ5c+bo6enh0bHGhqEyNVBTU0NRlPLXnEZFRTk5OSUmJubn59OJatUS3ccG3pQZGRnnzp27cuWKQCBACOFzpl1dXfLrdHZ2crlcJYtU31xfcI29fPly4FmNCq9vfFSOw+Hgg7tBdOnSpYULF5qYmHA4nO3bt9PpBEGsX7/+yZMnV69eRQj9/e9///TTTxFC7e3tCKFdu3bRE82ePXsmkUgGt1S0pqYmhNC4cePkEw0MDFpbWweY81BU5gBJpVKEEONVCBpJkikpKQRBrFu3jj740qyWBtiUZ86cOXjwYF5eno2NDU7Bp3FbWlrodSQSiVQqtbCwULJIxc0pgYMsrr3XAcRHBjKZrKmpaeLEiYOS240bN+Li4iorK728vMzNzW/fvt3c3Hzo0CH5dfz9/UmSPHXqVGlpqVAotLa2RgiZmJgghOLi4uRPiBQUFAxKqXozMDBACCn8zgdeD4NbmYMF/87lJzwzcnV13bJlS1lZ2b59+3CKZrU0kKZMSEhIS0u7du3ahAkT6ERbW1uBQPDs2TM65fHjxwih6dOnK1mkyuaU6+zsRP+pvdfBqHz+41DLy8ujKGru3LkIIRaLxTgGV92vv/7K5/OLi4tlMtmXX35pZ2eHej3K29DQ0NfX98yZMwKB4PPPP8eJkyZNIkmysLBwIFtX3bRp08aNG/fLL7/QKbdv3+7s7Jw1axYaQD0MbmUOFlNTU4Igmpub+11z37592dnZ9+7dw1eElddSXzRrSoqiduzY0djYmJmZyWL96afKYrGWLVt248aNnp4eHR0dhFBOTg5BEJ6enkoWqbV1RrjGzMzMBp7VqADHj/+np6ensbGxq6urqKgoKCjIysrK398fIWRvb9/Q0JCZmSmTyWpra+X/LRsZGT1//vzp06etra2MP3uZTPby5cu8vDw+n49/Xbm5uVKptKysrPfpqg0bNrx69So7O/uDDz7AKSRJBgQEnD59OikpqaWlpbu7u6qq6o8//hiiGiBJcuvWrRkZGWlpaS0tLcXFxRs2bLCwsAgMDFS3HgZemTk5OUM6v4fH49nZ2VVVVfW7Jh5l05c7lNeSkkz6ako/Pz8zMzPG2xbv379/+PDhkydPstlsQs6RI0cQQuHh4S9fvty9e3d7e3tBQUFMTIy/v7+Tk5PyRUo2pwpcYy4uLpp9ffQZtivlg0LFeSq3bt2aOnUq/udpbm6+f//+xMREfGrZwcGhvLz8xIkTQqEQIWRtbf3o0aPAwEA2m21paclisYRC4YoVK8rLy3FW9fX1ixYtIknS1tb266+/Dg4ORgjZ29tXVlbevXvX2tqay+XOnz//m2++UXIxNCMjg6KokJAQIyMjAwODVatWHTt2DCEkEonwxBfszTffDA0Nld+RV69ehYSEWFlZsVgsExMTHx+fkpKSQ4cO4QHOpEmTUlNTB7Heenp6YmJiHBwc2Gy2oaGhl5dXaWmpWvXw4sWLgVfmixcvLl++LBAIoqKiVNk7pNH8HrFYzGazJRIJ/piRkYFb0NjYeOPGjQpfDw4Opuf39FVLyvsYY1NSFOXl5YUQioiI6F3mvi4T03N3rl+//tZbb3E4HAsLi+DgYPn7JvtapGRzFEUVFBTMmzePPlNpbm7u5uZ2/fp1egUPDw9LS0v6zhxqrM/vGZvxUV345txBz1Zdy5Yte/LkyVDkPJz3Xw9/ZWoWH8vKylgslor/YIZOd3f3ggULkpOTR/7m6urqSJI8cuSIfOLYjo8wvv4//Z6qHyL0wLyoqAgfWGmlGINLW5WpXEdHx5UrV8rKyvBFBnt7+8jIyMjISPkn4gyz7u7uzMzM1tZWPz+/kb+5PXv2zJgxQywWI4Qoinr+/Hl+fj6++DNWQXzUspCQkLKyskePHgUEBNAXScFQaGhoeP/99x0dHdetW4dTQkNDV61a5efnp8qFmqGQl5eXnp6ek5OjfCbmSNhcbGxsYWHh5cuX8dTdrKwsS0vLBQsWXLp0aQhKOmJo+wBWPUMxTgwNDcXzeG1sbM6fPz+4mfdr586dOjo6kyZNwjcUDpFhG19rpTKRCuNrJa5cuRISEjKI5Rl7MjMzo6Oj5Z8kpIHROL4mqFF1q/m5c+d8fX1HV5lHgrFdbwRBnD17Ft7vOsKtWrUKjba3vML4GgAAmEF8BAAAZhAfAQCAGcRHAABgNirvvz537py2izDK4EchjOF6G7rHdoDBUlVVNdIeU9I/LV8/V5NmT6UHAIwEML8HAM3BTB0wosD5RwAAYAbxEQAAmEF8BAAAZhAfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGAG8REAAJhBfAQAAGYQHwEAgBnERwAAYAbxEQAAmEF8BAAAZhAfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGAG8REAAJhBfAQAAGYQHwEAgBnERwAAYAbxEQAAmEF8BAAAZhAfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGDG0nYBwGvt5MmTDQ0N8ilZWVkVFRX0x4CAAFNT02EvFwAIIURQFKXtMoDX1/r167/99lsOh9N7kUwmMzQ0fPHiBYsF/8WBdsD4GmjThx9+iBB6xURXV/ejjz6C4Ai0CI4fgTZRFGVpafnHH38wLr1586arq+swFwkAGhw/Am0iCGLNmjV6enq9F02YMGHu3LnDXyQAaBAfgZZ9+OGHnZ2dCol6enr//d//TRCEVooEAAbja6B9Dg4Ojx8/VkgsKipycXHRSnkAwOD4EWjf2rVr2Wy2fIq9vT0ER6B1EB+B9q1du7arq4v+yGazAwICtFgeADAYX4MRYcaMGUVFRbg3EgRRXl5ua2ur7UKB1x0cP4IR4ZNPPtHV1UUIEQQxa9YsCI5gJID4CEaEDz/8sKenByGkq6v7ySefaLs4ACAE8RGMEBYWFvPmzSMIoqenZ9WqVdouDgAIQXwEI8fHH39MUdTChQvNzc21XRYAEEIIUQNw9uxZbRcfAAD6tHLlyoGEuEG4+R+iJFAiLi4OIbR582YVV/7iiy/4fP4QF2pwFBQUxMfHQ/8fsXDfG4hBiI+rV68eeCZgrDp//jxSuZPMnz9/woQJQ1yiwRQfHw/9f8TCfW8g4PwjGEFGV3AEYx7ERwAAYAbxEQAAmEF8BAAAZhAfAQCA2ZDHxzlz5ujq6s6YMYNx6eXLl/X19X/44Yfeiz777DOBQEAQRGFhofI1B8XQ5X/kyBFTU1OCII4fPz7omfcrNzc3NDR0sHK7ePHioUOHuru7BytDRkPd1iMEbpr09HQ7OzuCIAiC+Pjjj+VXWLJkiUAg0NXVnTp16t27d4ezbJGRkc7OzkKhkMPh2Nvbb9++va2tjV6an58/b948Ho9nYWEREhLy6tUrVRb1q6enJy4uzs3NjU4Znv6mxJDHxzt37ixatKivpUqeHnTq1KmTJ0+qsuagGLr8t23bdvPmzSHKXLndu3cfPXo0LCxssDL09PQkSXLx4sVNTU2DlWdvr8Mzpeim8fHxefLkiUgkGj9+fFpa2qVLl+h1fvrpp/Pnz3/wwQclJSUzZ84czuJdu3Zt48aNT58+rauri46Ojo+Pp2/6LCkpWbJkyeLFi2trazMyMr777rsNGzb0u6hfZWVl//Vf/7VlyxaJREInDk9/U2bg98/0u9rixYtnzJihQf6nT59GCN27d0+D7/ZLIpG4uroORc69lZWVIYS++eab4dkcduDAAUdHx46OjkHPWSwWu7q6ymQyVVZeuXLlAO9hGHSD1fQq9v/eejeNSCT6/vvvdXR0LC0tm5qa6PScnJzly5cPvKjq8vDw6Orqoj/iOZ6VlZUURfn6+tra2vb09OBFMTExBEE8ePBA+SLlCgsLvb2909LSZsyY8cYbbygsVau/yRt43xum848KT4dW0ZC+fiQ5Obmmpmbo8h8UFEWdP3/+xIkT6n7x8ePH4eHhe/fuJUlycHNGCO3Zs6ewsDA+Pl6D744E2m36vprGzc0tKCiourp627Zt2iobLTs7Gz9uDjM2NkYISSSSrq6uS5cuubu707/NpUuXUhSVlZWlZFG/m3vjjTfS09PXrFnD+CZ0Lfa3YYqPjx8/njx5Mp/P53K5CxYsyGpvxrsAACAASURBVM/PRwjl5+dbWVkRBHHs2DG8GkVRMTExTk5OHA5HX18/ODgYpyusefjwYR6PJxAIampqtm7damlpWVpa2t3dHRERYWVlxeVyp0+fLn/XV2pq6uzZs0mS5PP5NjY2+/btCwoK2rp1a3l5OUEQ9vb2jCWJjY2dMmUKh8MxNDRcsWLFw4cPEUJJSUl8Pp/H42VlZS1dulQoFE6cOBEf5yKEfv75Z2dnZ319fZIkXVxcrly5om5FdXd3R0dHOzk5cblcY2NjW1vb6Ojo1atX997l9957T09Pj36Uw1dffcXn8wmCqKurQwgdPXqUoihPT89BzxkhZGho6O7uHh8fTw3BQFihLZRU+NGjR0mSNDU1Xb9+vYWFBUmSbm5ut2/fRgiJxeK+dkGh6RFCP/74o1Ao3L9//6DvC6PeTUOLiopydHQ8depUbm5u76Wa9UklvwvVVVdXc7lcW1vbJ0+etLW1WVlZ0YtEIhFCqKioSMkiDbYob0j7Wz8GcvCp+vjazs6uoqJCJpP99ttvb7/9NkmSjx49oijq999/RwglJCTgNXfu3EkQxF//+tfGxkaJRJKYmIj+M77uvSZCaNOmTQkJCd7e3g8ePNi2bRuHw7lw4UJjY2NYWJiOjs6dO3coisL3YB44cKC+vr6hoeHbb79ds2YNRVE+Pj4ikYgupEL+ERERenp6qampTU1NRUVFM2fONDY2fvHiBb3pq1evNjc319TULFiwgM/nd3Z24iOyPXv2NDQ01NfXz507d/z48Tg31cfX+/fv19XVzcrKkkgkv/76q5mZ2cKFC/va5TVr1piZmdHfjYmJQQjV1tZSFGVnZ+fs7DwUOWP4mo8qpz40GOMwtjVjhQcGBvL5/Pv370ul0pKSkjlz5ggEAjwMVLILCk2fnZ0tEAgiIyPVKiSl6fi6d9NQFCUSiSoqKiiKunnzpo6Ojo2NTVtbG/Xn8bVmfbKv34Xq2tvbBQKBWCymKOr69esIoZiYGPkVuFzu4sWLlSxSfVtvv/127/E1pU5/kzdqxtcCgcDGxobFYk2dOvXkyZNSqbT3yK6joyMuLu7dd9/dsmWLgYEBl8s1MjJSnu3Bgwc3btyYnp5uY2OTlJTk5eXl4+NjYGCwa9cuNpudkpIik8n27t27aNGiHTt2GBkZGRoafvrpp3PmzFGebUdHR2xsrLe399q1a/X19V1cXI4fP15XVydfZjc3N6FQaGJi4ufn197eXllZiRBauXLl7t27DQ0NjYyMPD096+vra2tr1aqozMzMWbNmeXp6crncmTNnLl++/MaNG/KvP6V3efLkyX1l0t7eXlFRgf97D27ONAcHB4RQcXGxWns3EIwVjhBisVj4kMrZ2TkpKam1tTUlJUWtnD08PFpaWsLDw4eg1IoYm0aeq6vr5s2bnz59umPHDvl0zfqkVCpl/F2oVebo6GgLC4uoqCiEEL4eLT/0Rgix2eyOjg4li9TaHKPh72+YFuY/uri46Ovr9z7qfvz4sUQiWbx4sQZ5lpaWSiSSadOm4Y9cLtfc3Pzhw4dFRUVNTU3vvfcevaauru6mTZuU51ZSUtLW1jZ79mw6Zc6cOXp6enjspgC/214mkymk41Ou6k5NkEqllNwgoru7m81mK/S5ftXU1FAUxePxBj1nGs785cuXmn19IPqqcITQ7NmzeTweHnWOTIxNoyAqKsrJySkxMRGfhsI065N9/S5UL3BGRsa5c+euXLkiEAgQQvicqfzL1BBCnZ2dXC5XySLVN9cXbfU37cwPZ7PZvft3VVUVQsjExESDDNvb2xFCu3btIv7j2bNnEomkpaUFIWRgYKBWbngywbhx4+QTDQwMWltblX/x0qVLCxcuNDEx4XA427dvV28fEEIILVu27Ndff83Kyuro6Pjll18yMzP/8pe/qBvFpFIpQkjhVPeg5EzDnR5vaEThcDjqHrMPJ8amUUCSZEpKCkEQ69atow++NOuTff0uVCztmTNnDh48mJeXZ2Njg1PwKV38s8IkEolUKrWwsFCySMXNKaGt/qaF+NjV1dXQ0CB/HhfD/3/UmlBKw1E1Li5O/txBQUEBfh4MfWFBRTieKvS8pqamiRMnKvlWZWWll5eXubn57du3m5ubDx06pPZuILRnz5533nnH399fKBR6e3uvXr1afhKoinBnUjh0HZScaXhgPiiHBoNIJpP120zaxdg0vbm6um7ZsqWsrGzfvn04RbM+2dfvQpWiJiQkpKWlXbt2Tf6hSra2tgKB4NmzZ3TK48ePEULTp09XskiVzSmnrf42CM9/VNe//vWvnp6e3vNdp02bpqOjc/36ddXnlNImTZpEkiS+00aejY2NkZHRTz/9hE9gq2jatGnjxo375Zdf6JTbt293dnbOmjVLybeKi4tlMtmXX35pZ2eHNJ2cVFJSUl5eXltby2L13zQsFotxmIlv12lubh70nGk4czMzs36zGk55eXkURc2dOxepsAtawdg0jPbt25ednX3v3j18JKFZn+zrd6EcRVE7duxobGzMzMxU6C0sFmvZsmU3btzo6enR0dFBCOXk5BAE4enpqWSRWltnpK3+NkzHj52dnc3NzV1dXXfv3hWLxdbW1v7+/grrmJiYrFy58sKFC8nJyS0tLUVFRarPziNJMiAg4PTp00lJSS0tLd3d3VVVVX/88QeHwwkLC7tx44ZYLK6uru7p6Wltbb1//z5CyMjI6Pnz50+fPm1tbVX4IZEkuXXr1oyMjLS0tJaWluLi4g0bNlhYWAQGBiopA+7Hubm5Uqm0rKyM8cRQvzZu3GhlZSV/L5cS9vb2DQ0NmZmZMpmstraW/tfN4/Hs7Ozw+YrBzZmGM3dxcVEltyHV09PT2NjY1dVVVFQUFBRkZWWFu5aSXVBo+pycnGGb38PYNIzwKJs+AaJZn+zrd4EQ8vPzMzMzY7xt8f79+4cPHz558iSbzSbkHDlyBCEUHh7+8uXL3bt3t7e3FxQUxMTE+Pv7Ozk5KV+kZHOq0Fp/G8jFbxXnN6SkpCxatMjU1JTFYo0fP/7DDz989uwZRVEJCQn4nAWPx/P09KQoqrW19fPPPx8/fvy4cePmz58fERGBEJo4ceLnn38uv+ahQ4fwkfakSZNSU1PxVl69ehUSEmJlZcVisUxMTHx8fEpKSvCiY8eOubi4kCRJkuSbb76ZmJhIUdTdu3etra25XO78+fN37dqlUJKenp6YmBgHBwc2m21oaOjl5VVaWkpRVGJiIj5V7ODgUF5efuLECaFQiBCytrZ+9OhRSEiIkZGRgYHBqlWr8PQ9kUgUFBSE/+/x+Xxvb2/ldXXt2rXx48fTrcNms6dMmZKens64y/X19YsWLSJJ0tbW9uuvv8bTRe3t7SsrK8ViMZvNlkgkg54zXsHDw8PS0pK+U0IJdedYKPQK5RUeGBjIZrMtLS1ZLJZQKFyxYkV5eXm/uyDf9C9evLh8+bJAIIiKilK9kJhm83sUmiYjIwNfzjY2Nt64caPCysHBwfT8Hs36ZF+/Cy8vL4RQRERE7xL2dZmYnrtz/fr1t956i8PhWFhYBAcH40t/yhcp2RxFUQUFBfPmzaPPVJqbm7u5uV2/fp1eQfX+Jm/g83uGIz4C1SUmJgYFBdEfX716tXnzZg6HIx/pVFFWVsZiseh4N4g5UxRVV1dHkuSRI0dUWXlI7y8MDAw0MjIaosz7pVn/7900WtHd3b1gwYLk5OSRvzm1+pu8UTP/EajixYsXYrH4008/pVP09PSsrKxkMpm6p9Ls7e0jIyMjIyPxgHoQc0YI7dmzZ8aMGWKxWN0vDgUtPtxFMwpNoxXd3d2ZmZmtra1+fn4jf3Na7G8QH4fVw4cPib4FBASw2ezk5OSXL1/KZLLnz5+fOnUqIiLCz88Pj5jUEhoaumrVKj8/v+bmZi6XO1g5x8bGFhYWXr58WbN76gH6c9NopQB5eXnp6ek5OTnKZ2KOhM1pub8N5OATxteD7saNG++++65QKNTV1dXX13dzc0tMTNTgySW0K1euhISEDFbOmZmZ0dHR8k926dfQja9DQ0PxRGgbG5vz588PxSaUG2D/p5sG9EWD/iZv4H2PoAZwy/e5c+d8fX0HkgMY8/BzAwf+ps0RCPr/CDfwvgfjawAAYAbxEQAAmEF8BAAAZhAfAQCA2SDcf33u3LmBZwLGKnxn2JjsJPhBD2Ny18aGqqqqgT6sZCAXvzV7VjsAAAyPAc7vGYTjR5jfAJSA+T1AW+h30moMzj8CAAAziI8AAMAM4iMAADCD+AgAAMwgPgIAADOIjwAAwExr8TE9Pd3Ozk7+6YcsFsvY2Pjdd9/NyMigV7t8+bK+vv4PP/zQO4fPPvtMIBAQBIFfP6RkzUExdPkfOXIEv7bp+PHjCotyc3NDQ0Ppj48ePfr666+nTp0qFAr19PRMTEwmT57s7e39z3/+EzFVKX67wLp16yoqKnAO//M//zNhwgSCIHR0dBwdHXNzc+nM//KXvwiFQh0dncmTJ4eEhBw6dGjUPXp2hMOtKd9MH3/8sfwKS5YsEQgEurq6U6dO1fhVLZqJjIx0dnYWCoUcDsfe3n779u3yj+/Nz8+fN28ej8ezsLAICQmRf8mokkXKyWSy6Ohoe3t7PT09AwODadOmPX36VGEdqVQ6efLkXbt2IYQuXryohT458PnhA8lBJBLp6+vjvxsaGnJzcydPnowQOnPmDE7Mzs4WCoUXL15k/Prp06cRQvfu3et3zYEb0vzLysoQQt988418YkRExAcffNDS0oI/pqSk6OnpzZ8//8cff2xsbJRKpeXl5T/88IOHh0dgYCD9LbpKu7u7X758+fe//53H45mamtbV1dHrIITefvvt3sX417/+tXjxYvx3fHy8u7t7Y2PjAHdtSN+voF1q9X+F1hSJRPh1QNnZ2fKr5eTk0C+cGU7u7u6JiYn19fUtLS1nz55ls9nvv/8+XvTbb79xudzw8PC2trabN28aGxsHBAT0u6hfXl5eTk5Ot27dwg9s9vT0LC4uVlhny5YtCKGdO3fij+r2yVH//hn5+IhduXIFIdTve6ww+fg46CQSiaur61Dk3Fvv+HjgwAFHR8eOjg78saCgQFdXd+HChb2faFteXs4YH2nbt2+X/5dDqRYfKYoSi8Wurq4DeTovNcTxcVDaSONMVO//Cq1JUZRIJPr+++91dHQsLS2bmprodG3FRw8PD/nH0K5evRohhF/H5uvra2trS78bKyYmhiCIBw8eKF+k3OnTpwmCKCoqUrLOv//97yVLlsjHR0rNPjkG3z9jY2ODEGpqalJlZc3eMa2i5OTkmpqaoctficePH4eHh+/du5ckSZyyf//+7u7uAwcO9H57tZ2dXe+BuTx7e3uE0IsXL9Qtxp49ewoLC+Pj49X94rAZlDYa6obu3ZqYm5tbUFBQdXX1tm3bhm7rKsrOzqbfJYsQMjY2RghJJJKurq5Lly65u7vTv7WlS5dSFJWVlaVkUb+b++abb2bOnKnkfa0dHR3BwcG9+94w98kRFx+LiooQQu7u7gih/Px8KysrgiDwu1IRQhRFxcTEODk5cTgcfX19/NLO3msePnyYx+MJBIKampqtW7daWlqWlpZ2d3dHRERYWVlxudzp06fL3zyempo6e/ZskiT5fL6Njc2+ffuCgoK2bt1aXl5OEIS9vT1jSWJjY6dMmcLhcAwNDVesWPHw4UOEUFJSEp/P5/F4WVlZS5cuFQqFEydOxMe5CKGff/7Z2dlZX1+fJEkXFxd8sNzb0aNHKYqiX6ze2dmZm5trZGSE33yvLnxw+sYbb6j7RUNDQ3d39/j4eGrob6Hrqz7FYrGenh5+4ytC6KuvvuLz+QRB1NXVKbTR0aNHSZI0NTVdv369hYUFSZJubm74LeSqZ4IQ+vHHHwf3ddgKrSkvKirK0dHx1KlT8ieC+60T5X1MST9XXXV1NZfLtbW1ffLkSVtbG363O4bfRltUVKRkkfLMOzs7b926NWPGDCXr7Ny586uvvjIxMVFIH84+idBIOv8okUhycnKsra2XLFnS1taGE3///XeEUEJCAv64c+dOgiD++te/NjY2SiSSxMRE9J/xde81EUKbNm1KSEjw9vZ+8ODBtm3bOBzOhQsXGhsbw8LCdHR07ty5Q1FUXFwcQujAgQP19fUNDQ3ffvvtmjVrKIry8fERiUR0URXyj4iI0NPTS01NbWpqKioqmjlzprGx8YsXL+hNX716tbm5uaamZsGCBXw+v7Ozk6Ko8+fP79mzp6Ghob6+fu7cuePHj8e5KYyv7ezsnJ2d6U0/evQIITR37lx1q7SxsfFvf/sbj8fz8PCQXwepNr6mKApfHRrIGQwVxzhK6nPNmjVmZmb0mjExMQih2tpaqlcbBQYG8vn8+/fvS6XSkpKSOXPmCAQCPEhUPZPs7GyBQBAZGdlvmVXs/wqtiYlEooqKCoqibt68qaOjY2Njg/u8/Phasz7WVz9XXXt7u0AgEIvFFEVdv34dyb35GuNyuYsXL1aySHn++GrhjBkzFi5caG5uzuFwJk+efOzYMXqcnp+fj19DX1tbi/48vqbU6ZNjYXzd3NyMr+XxeDz8z3DNmjWM7yrr6OiIi4t79913t2zZYmBgwOVyjYyMlGd+8ODBjRs3pqen29jYJCUleXl5+fj4GBgY7Nq1i81mp6SkyGSyvXv3Llq0aMeOHUZGRoaGhp9++umcOXOUZ9vR0REbG+vt7b127Vp9fX0XF5fjx4/X1dWdOHGCXsfNzU0oFJqYmPj5+bW3t1dWViKEVq5cuXv3bkNDQyMjI09Pz/r6etwD5LW3t1dUVOB/xVhLSwtCaNy4ccpLRaOr1NDQMCAgICwsDF/g1oCDgwNCqK8Xxg8WVepTRSwWCx9wOTs7JyUltba2pqSkqJWDh4dHS0tLeHi4uptm1Ls1Fbi6um7evPnp06c7duyQT9esj0mlUsZ+rlaZo6OjLSwsoqKiEEL4erT80BshxGazOzo6lCxSnj++Mm5iYrJ///6SkpKXL1+uWLFi48aN//jHP/COBwUFJSUl9fX14emTmPbjI32wI5PJqqqqNm/eLBaLp0+fXldXp7Dm48ePJRLJ4sWLNdhKaWmpRCKZNm0a/sjlcs3NzR8+fFhUVNTU1PTee+/Ra+rq6m7atEl5biUlJW1tbbNnz6ZT5syZo6enh0dzCvA79nq/Zhr/D+g9X6GmpoaiKPk3YeLI2N7errDmuXPnbG1tcSicMmUKfRKNrtLg4GCKovT19TV+NyYuxsuXLzX7uorUqk/VzZ49m8fj4TGptvRuzd6ioqKcnJwSExPz8/PpRM36WF/9XPUCZ2RknDt37sqVKwKBACGEz5l2dXXJr9PZ2cnlcpUsUr4JDoeDEJo6daqbm5uRkZG+vv7evXv19fVx6A8LC/viiy8sLS37+vrw9ElM+/GRxmKxLC0tAwICjhw5UlpaeuDAAYUV8JNWe5+SUAUOLrt27aLnBj579kwikeBDMwMDA7Vyw5ePFA7oDAwMWltblX/x0qVLCxcuNDEx4XA4+LJyb1KpFP2nD2HW1tYcDufx48cKa65evbqiosLa2trMzOzBgwempqYKK4SHh5ubm4eFheGTA/J6enp6b7q7u1shkuK+jos0dDSuz35xOJzeR+jDqXdr9kaSZEpKCkEQ69atow++NKuTvvq5iqU9c+bMwYMH8/Ly8GVShBA+aYt/JphEIpFKpRYWFkoWKd8KXkH+AEhPT8/a2rq8vDw/P7+4uPizzz5T8vXh6ZPYCIqPNHxV6/79+wrp+P+V6hNQ5eGoGhcXJ39yoaCgYMKECejPTaUKHE8VempTU5PyhxVXVlZ6eXmZm5vfvn27ubn50KFDjKvh5pc/riRJ8t13362trb1165Za5RQIBAcPHmxtbf3yyy/l042MjJ4/f957/YqKikmTJsmndHZ20kUaOprVZ79kMtnAMxmg3q3JyNXVdcuWLWVlZfv27cMpmtVJX/1claImJCSkpaVdu3YN/ygwW1tbgUDw7NkzOgX/n54+fbqSRco3NG7cOAcHB4UfeFdXl76+fnJy8tWrV3V0dHBwx7uzf/9+giB++eUXvObw9ElsJMbHX3/9FSHk5OSkkD5t2jQdHR18VlhdkyZNIkkS32kjz8bGxsjI6KefflIrt2nTpo0bN45uMITQ7du3Ozs7Z82apeRbxcXFMpnsyy+/tLOzI0myr8lJ+F6a5uZm+cS9e/ey2ezg4ODe43TlPvnkk7fffjs7O1v+NQDvvPNOdXX1zZs35dekKOpvf/vb22+/LZ+Ii2FmZqbWRtWlvD5ZLJa6e43l5eVRFIUv+mucyQAxtiajffv2TZ48+d69e/ijZn2sr36uHEVRISEhxcXFmZmZCkesLBZr2bJlN27coAccOTk5BEF4enoqWdTvFn19fe/du/fkyRP8USKRPHv2zMXFJSUlRT6yy1+foU81DE+fxEZEfOzo6MCXrp4/f56SkrJr1y5jY+PNmzcrrGZiYrJy5coLFy4kJye3tLQUFRWpfv6eJMmAgIDTp08nJSW1tLR0d3dXVVX98ccfHA4nLCzsxo0bYrG4urq6p6entbUV/2fDB1lPnz5tbW1V+GmRJLl169aMjIy0tLSWlpbi4uINGzZYWFgEBgYqKQOeCZGbmyuVSsvKyvo6ucbj8ezs7PDJBNqsWbNSU1N//fXXhQsX/vjjj3/88UdXV9ezZ89SU1MbGhqUbJQgiKNHjxIEIRaLGxsbcWJUVJSBgcGqVav++c9/tre3v3r16v/9v//30UcfdXV1KdzxhouhZJ7aoFBen/b29g0NDZmZmTKZrLa2Vv6ApXcb9fT0NDY2dnV1FRUVBQUFWVlZ+fv7q5VJTk7OIM7vYWzNviohJSWFvtyhWR/rq58jhPz8/MzMzBhvW7x///7hw4dPnjzJZrPl7089cuQIQig8PPzly5e7d+9ub28vKCiIiYnx9/fHhy9KFinZHEJoy5Yt1tbW/v7+lZWV9fX1ISEhHR0dCleo+jI8ffL/DOTi90Dm92RkZPS+qMfhcBwcHL788ks8JyMhIQGf4+DxePh6f2tr6+effz5+/Phx48bNnz8/IiICITRx4sTPP/9cfs1Dhw7hw+9JkyalpqbiLb569SokJMTKyorFYpmYmPj4+JSUlOBFx44dc3FxIUmSJMk333wzMTGRoqi7d+9aW1tzudz58+fv2rVLoSQ9PT0xMTEODg5sNtvQ0NDLy6u0tJSiqMTERHz+2MHBoby8/MSJE0KhECFkbW396NGjkJAQIyMjHJvwVEqRSBQUFIT/GfL5fHzjkFgsZrPZEolEodIqKiqCgoKmTp3K5/PxvdULFizYsWPHjRs3KIr697//7ejoiGtywoQJ69evp7+IY4SBgcGBAwforD7//HNbW1s9PT0ul+vs7BwREUFPq6J5eHhYWlrSEy80oOIci77qk6Ko+vr6RYsW4f39+uuv8aRXe3v7yspK+TZ68eJFYGAgm822tLRksVhCoXDFihXl5eXqZnL58mWBQBAVFdVvmVXs/wqtSfd8Y2PjjRs3KqwcHBxMz+/RrI/11c+9vLwQQhEREb1L2Ne1YHruzvXr19966y0Oh2NhYREcHCyVSunv9rVIyeaw33///cMPPzQ0NORwOG+99VZOTk7vdRjn96jeJ0f9/YWAUVlZGYvFoiO7ttTV1ZEkeeTIkYFkMpz3XwcGBhoZGQ3PtiiV+/8Iac3u7u4FCxYkJyeP6s2p1SfHwvxH0Ju9vX1kZGRkZKT8M1SG3549e2bMmCEWi7VYBnWNwGcOjYTW7O7uzszMbG1t9fPzG9WbG+Y+CfFxhAoNDV21apWfn58qp/aHQmxsbGFh4eXLlzWeOwloWm/NvLy89PT0nJwc5TMxR/jmhr9PQnwcufbv3y8Wi3vPAx0GWVlZr169ysvLMzQ0HP6tayYsLCwlJaW5udnW1vbChQvaLo4iLbYmQmjx4sXff/89fQf6aNycVvokQQ3gNm94/y/oF7z/GmjLwPseHD8CAAAziI8AAMAM4iMAADCD+AgAAMwUH9avAXwSFABG+JkaY7KT4BvdxuSujQ23bt3S7JH7tAFdvy4oKIiNjR3I5gGQd/Xq1WnTpg3PowfA6wA/GEnjrw8oPgIwuAiCOHv2LH55HgBaB+cfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGAG8REAAJhBfAQAAGYQHwEAgBnERwAAYAbxEQAAmEF8BAAAZhAfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGAG8REAAJhBfAQAAGYQHwEAgBnERwAAYAbxEQAAmEF8BAAAZhAfAQCAGcRHAABgBvERAACYQXwEAABmEB8BAIAZxEcAAGAG8REAAJhBfAQAAGYQHwEAgBlBUZS2ywBeX5988sm9e/foj7///vv48eN5PB7+yGazs7OzJ0yYoKXSgdcdS9sFAK81Jyen1NRU+ZTm5mb6b2dnZwiOQItgfA20ae3atQRBMC5is9n+/v7DWxwA/gTG10DLZs+efffu3d79kCCIJ0+e2NjYaKNQACAEx49A6z755BNdXV2FRB0dnblz50JwBNoF8RFomZ+fX09Pj0Kijo7OJ598opXyAECD+Ai0zNTU1N3dXeEQkqIob29vbRUJAAziI9C+jz/+WP78o66u7rvvvmtqaqrFIgGAID6CkcDHx4fF+v+nmlEUtXbtWi2WBwAM4iPQPqFQuHTpUjpEslgsT09P7RYJAATxEYwQa9eu7e7uRgixWKzly5cLhUJtlwgAiI9gZPjLX/6Cbyvs7u5es2aNtosDAEIQH8EIQZKkj48PQojP57///vvaLg4ACI3J+6+rqqpu3ryp7VIAtU2cOBEhNGfOnKysLG2XBaht0qRJrq6u2i7FYKPGnLNnz2q7UgF47axc/4QDVQAAIABJREFUuVLbP/3BNwaPHzHq9buvfNWqVQih8+fPa7sgmtu/f/+OHTt632547tw5X1/f17BNRwvc98YeOP8IRpCQkJDewREAbYH4CEYQ+VniAGgdxEcAAGAG8REAAJhBfAQAAGYQHwEAgBnER62JjIx0dnYWCoUcDsfe3n779u1tbW3DXIbLly/r6+v/8MMPw7zdoZabmxsaGpqenm5nZ0cQBEEQH3/8sfwKS5YsEQgEurq6U6dOvXv37nCWTXm75+fnz5s3j8fjWVhYhISEvHr1SpVFyslksujoaHt7ez09PQMDg2nTpj19+lRhHalUOnny5F27diGELl68eOjQIXw7/OtO2xMwBx+eH67tUvTP3d09MTGxvr6+paXl7NmzbDb7/fffH0iGK1euVHeObnZ2tlAovHjx4kC2OwzUatOIiIgPPvigpaUFfxSJROPHj0cIZWdny6+Wk5OzfPnyQS6oCpS0+2+//cblcsPDw9va2m7evGlsbBwQENDvon55eXk5OTndunVLJpM9f/7c09OzuLhYYZ0tW7YghHbu3Ik/xsfHu7u7NzY2qrgJDfreqDAK4oi6Rkt89PDw6Orqoj+uXr0aIVRZWalxhiOwj0okEldX14Hno3qbHjhwwNHRsaOjg04RiUTff/+9jo6OpaVlU1MTna6t+Kik3X19fW1tbXt6evCimJgYgiAePHigfJFyp0+fJgiiqKhIyTr//ve/lyxZIh8fKYoSi8Wurq4ymUyVnRqBfW9QwPhaa7Kzs+XnQhsbGyOEJBKJ9ko0+JKTk2tqaoZtc48fPw4PD9+7dy9JkvLpbm5uQUFB1dXV27ZtG7bC9KWvdu/q6rp06ZK7uzv9wtulS5dSFJWVlaVkUb+b++abb2bOnOni4tLXCh0dHcHBwfHx8Qrpe/bsKSws7J3+WoH4yCA1NXX27NkkSfL5fBsbm3379iGEKIqKjY2dMmUKh8MxNDRcsWLFw4cPEUJJSUl8Pp/H42VlZS1dulQoFE6cOPH06dMIoSlTphAEoaOjM2vWLBz4tm/frq+vT5Lk3/72N4WNVldXc7lcW1vbYdvN/Px8KysrgiCOHTumfEeOHj1KkqSpqen69estLCxIknRzc7t9+zZCSCwW6+npmZub4zy/+uorPp9PEERdXV1QUNDWrVvLy8sJgrC3t0cI/fjjj0KhcP/+/UO0R0ePHqUoivHZulFRUY6OjqdOncrNze29VIPGRQh1d3dHRERYWVlxudzp06drduM/3e5Pnjxpa2uzsrKiF4lEIoRQUVGRkkXKM+/s7Lx169aMGTOUrLNz586vvvrKxMREId3Q0NDd3T0+Pp56nW/r1ObB69AY4Pg6Li4OIXTgwIH6+vqGhoZvv/12zZo1FEVFRETo6emlpqY2NTUVFRXNnDnT2Nj4xYsXFEXt3LkTIXT16tXm5uaampoFCxbw+fzOzs6uri4bGxsrKyv58dTmzZvj4uIUNtre3i4QCMRiscbFpjQa4/z+++8IoYSEBPyxrx2hKCowMJDP59+/f18qlZaUlMyZM0cgEOBR4Zo1a8zMzOg8Y2JiEEK1tbUURfn4+IhEInpRdna2QCCIjIxUd9dUbFM7OztnZ2eFRJFIVFFRQVHUzZs3dXR0bGxs2traqD+PrzVoXIqitm3bxuFwLly40NjYGBYWpqOjc+fOHbX2S77dr1+/jhCKiYmRX4HL5S5evFjJIuX5V1RUIIRmzJixcOFCc3NzDoczefLkY8eO0eP0/Px8T09PiqJqa2vRn8fXFEWFhoYihO7du9fvjsD4+rUgk8n27t27aNGiHTt2GBkZGRoafvrpp3PmzOno6IiNjfX29l67dq2+vr6Li8vx48fr6upOnDhBf9fNzU0oFJqYmPj5+bW3t1dWVurq6m7atKmysjIjIwOvI5FI0tPT161bp7Dd6OhoCwuLqKio4dvVvvXeEZzOYrHwEZazs3NSUlJra2tKSopaOXt4eLS0tISHhw9BqVF7e3tFRQU+sGLk6uq6efPmp0+f7tixQz5ds8aVSqVJSUleXl4+Pj4GBga7du1is9nqVoh8u+Pr0Qq3n7PZ7I6ODiWLlOePr4ybmJjs37+/pKTk5cuXK1as2Lhx4z/+8Q+840FBQUlJSX193cHBASFUXFys1k6NJRAf/6SoqKipqem9996jU3CMKykpaWtrmz17Np0+Z84cPT09PMZUoKenhxCSyWQIoc8++0xfX58+iZOWlrZixQqFlwdkZGScO3fuypUrAoFgKHZKY/I7omD27Nk8Hg8PQkeImpoaiqLwQ8j7EhUV5eTklJiYmJ+fTydq1rilpaUSiWTatGk4ncvlmpubq1UhCu2Oz5l2dXXJr9PZ2cnlcpUsUr4JDoeDEJo6daqbm5uRkZG+vv7evXv19fVx6A8LC/viiy8sLS37+jquzJcvX6q+U2MMxMc/aWlpQQgZGBgopDc1NSGExo0bJ59oYGDQ2tqqPMNx48Z98cUXN2/e/N///V+E0DfffCMWi+VXOHPmzMGDB/Py8mxsbAZc/GHF4XDwoGyEkEql6D8RoS8kSaakpBAEsW7dOvrgS7PGbW9vRwjt2rWL+I9nz56pfnmtd7vjc7i4B2ISiUQqlVpYWChZpHwreIW6ujo6RU9Pz9raury8PD8/v7i4+LPPPlPydRx/ccW+niA+/smECRPQn/sThiOmwg+mqakJP/JaObFYzGaz4+Libty4MWnSJPkBYEJCQlpa2rVr1/B2RxGZTKbi7g8b/GPud1azq6vrli1bysrK8GU3pGnj4gsaCqeSCwoKVCkqY7vb2toKBIJnz57RKY8fP0YITZ8+Xcki5RsaN26cg4PD/fv35RO7urr09fWTk5OvXr2qo6ODgzvenf379xME8csvv+A1Ozs70X8q9vUE8fFPbGxsjIyMfvrpJ4X0adOmjRs3ju43CKHbt293dnbOmjWr3zwnTpy4evXqCxcuhIeHBwUF4USKokJCQoqLizMzMxWOXEaFvLw8iqLmzp2LEGKxWIxj8GFmampKEERzc3O/a+7bt2/y5Mn37t3DHzVr3EmTJpEkWVhYqFYhlbQ7i8VatmzZjRs3enp6cEpOTg5BEJ6enkoW9btFX1/fe/fuPXnyBH+USCTPnj1zcXFJSUmRj+zy12foUw24Ms3MzNTax7EE4uOfcDicsLCwGzduiMXi6urqnp6e1tbW+/fvkyS5devWjIyMtLS0lpaW4uLiDRs2WFhYBAYGqpLt1q1bu7q6Ghsb33nnHZxy//79w4cPnzx5ks1mE3KOHDkylPs3ID09PY2NjV1dXUVFRUFBQVZWVv7+/gghe3v7hoaGzMxMmUxWW1srf5hjZGT0/Pnzp0+ftra2ymSynJycoZvfw+Px7Ozsqqqq+l0Tj7Lpyx2aNS5JkgEBAadPn05KSmppaenu7q6qqvrjjz8QQn5+fmZmZoy3LSpv9/Dw8JcvX+7evbu9vb2goCAmJsbf39/JyUn5IiWbQwht2bLF2tra39+/srKyvr4+JCSko6ND4QpVX3BlKpk7OfYN14Xy4TPw+2eOHTvm4uJCkiRJkm+++WZiYiJFUT09PTExMQ4ODmw229DQ0MvLq7S0lKKoxMREfBrbwcGhvLz8xIkT+PKLtbX1o0eP6DwXLVp06tQp+mNf1wQV5nCoRd05FgkJCfjEFo/H8/T0VL4jgYGBbDbb0tKSxWIJhcIVK1aUl5fjfOrr6xctWkSSpK2t7ddffx0cHIwQsre3r6ysvHv3rrW1NZfLnT9//osXLy5fviwQCKKiotTdNRXbFJ/KkEgk+GNGRgY+m2FsbLxx40aFlYODg+n5PZo17qtXr0JCQqysrFgslomJiY+PT0lJCUVRXl5eCKGIiIjeJey33a9fv/7WW29xOBwLC4vg4GCpVEp/t69FSjaH/f777x9++KGhoSGHw3nrrbdycnJ6r8M4v8fDw8PS0pKeDKTEWJ3fA/Fx7BjSPhoYGGhkZDREmfdLxTYtKytjsVipqanDUCQluru7FyxYkJycPKo3V1dXR5LkkSNHVFl5rMZHGF8DVY38B7rY29tHRkZGRkYO/5OQaN3d3ZmZma2trX5+fqN6c3v27JkxY4bCdIvXDcRHMKaEhoauWrXKz89PlQs1QyEvLy89PT0nJ0f5TMwRvrnY2NjCwsLLly+z2exBzHbUgfgI+hcWFpaSktLc3Gxra3vhwgVtF6cf+/fvF4vFBw4c0MrWFy9e/P3339M3pI/GzWVlZb169SovL8/Q0HAQsx2N4HVxoH/R0dHR0dHaLoUalixZgh/YBTSwfPny5cuXa7sUIwIcPwIAADOIjwAAwAziIwAAMIP4CAAAzMbs9ZlVq1ZpuwjD7datW2iM7ji+0W1M7trYcOvWLXwz/hgDx48AAMBszB4/nj9/XttFGG748GpM7vi5c+d8fX3H5K6NDWP10B6OHwEAgBnERwAAYAbxEQAAmEF8BAAAZhAfAQCA2eseH0tLS7/++uupU6cKBAIWi6Wvr+/o6Ojh4aHii5Y009PTExcX5+bmRqekp6fb2dnJP3BfT0/P1NR04cKFMTExjY2NQ1eYMSk3N/f/Y+/eA5q40sbxnwm5hySAcisY5KaIoLx4R121dN1VKnIVXG0XW79Sq0UUEQFFRMBaLPCioGuldCtWBfQFq2L7aostRV2tsiDeELlILfc7AUlgfn/Mr3mzYTIECATx+fzFnJmcec6ZycNcTmZCQ0Ple/W9996TX2D58uV8Pl9LS2v69OnK3kwwQqKiomxtbQUCAYvFsrKy2rVrl/zTKvPz8xcuXMjlco2NjUNCQog3Xw84i5pEIomNjbWysmIymTo6OnZ2dhUVFQrLdHd329jY7NmzByF08eLFQ4cOjf3HfY4GTT+gV/1Uf374yZMnGQzGn/70p6tXrzY3N3d3d5eVlZ09e9bJyekf//jHCIX39OnThQsXIoRmzpypMMvS0lIoFOI4Trzp5ccff/Tz88MwzNjY+M6dOwPWPF6f4YwP8pnwERERq1atamtrIyYtLS0nTJiAELp06ZL8Yrm5ubL3K4ymJUuWJCcnNzY2trW1nTt3jsFg/PWvfyVmPXjwgMPh7N27t6Ojo6CgYOLEiRs2bBhw1oDc3d2nTp1669YtiUTy8uVLV1fX4uJihWV27NiB5N6vkJiYuGTJkubmZhVXMV73vTc3P968eVNLS+vtt9+WSCQKs65evXrkyJGRiK2wsNDDwyM9Pd3BwYEiP8rLzMyk0WgGBgYtLS3UlY/oPioWixcsWKCpSlTPjwcPHpwyZUpXV5esxNLS8vTp0zQazcTERL4PNZUfXVxcpFKpbHLNmjUIoaqqKhzHfXx8zM3NZe97iYuLwzDs0aNH1LOonTlzBsOwoqIiimV++eUX4nFw8u+fCQgIWLBgQf9vB6nxmh/f3PPr6Ojo3t7egwcP0umKg+T/8pe/bN26dSRWOnPmzPPnz69bt476NfbyvLy8/Pz86urqjh8/PhIhqSg1NbWurm4sVELh2bNne/fu3b9/P5vNli93cnIKDAz87bffdu7cOXJrV9GlS5dkr05ECE2cOBEhJBaLpVLp5cuXlyxZgmEYMWvFihU4jufk5FDMGnB1x44dc3R0pHgHYVdXV3BwcGJiokJ5ZGRkYWFh//I3yhuaH3t6eq5fvz5hwoS5c+dSLIbjeHx8/LRp01gslq6urpub2+PHjxFCKSkpPB6Py+Xm5OSsWLFCIBCYmpqeOXMGITRt2jQMw2g02qxZs8RiMUJo165dQqGQzWZ/9dVXQ4uWeI1qbm7u0D6uYqMCAgKYTKbsSdRbtmzh8XgYhjU0NAQGBgYFBZWVlWEYZmVllZSUxGazDQwMPvroI2NjYzab7eTkdPv27UFVghC6evWqel/3mpSUhOM46Vuho6Ojp0yZcvLkyWvXrqneJxQbGiHU29sbEREhEok4HM6MGTOIg9zB+u233zgcjrm5+fPnzzs6OkQikWwW8fLFoqIiilnUlff09Ny6dcvBwYFimfDw8C1btujr6yuU6+rqLlmyJDExEcfxwTZq/NDgsesIUeVc7OnTpwih+fPnUy8WERHBZDJPnTrV0tJSVFTk6Og4ceLEmpoaHMfDw8MRQtevX29tba2rq1u8eDGPx+vp6ZFKpZMnTxaJRPLnUNu3b09ISJCved68eSqeX+M43tbWhhCaNGkSdbQqnuNQNGrdunWGhoayJePi4hBC9fX1OI57enpaWlrKZvn7+/N4vIcPH3Z3d5eUlMyZM4fP5xMniapXcunSJT6fHxUVNWDMKp5fW1hY2NraKhRaWlqWl5fjOF5QUECj0SZPntzR0YH/5/n1EDY0juM7d+5ksVhZWVnNzc1hYWE0Gk2Vy8TyOjs7+Xx+QEAAjuM3btxA/V7wy+FwnJ2dKWZR119eXo4QcnBwWLp0qZGREYvFsrGxOXr0qOw8PT8/39XVFVfyftfQ0FCE0P379wdsCJxfjytExtHW1qZYpqurKz4+3sPDY/369UKh0N7e/vjx4w0NDSdOnJAt4+TkJBAI9PX1fX19Ozs7q6qqtLS0tm3bVlVVdeHCBWIZsVh8/vz5Dz74YMjR8vl8DMPa29uHXIOMKo1SEZ1OJw64bG1tU1JS2tvb09LSBlWDi4tLW1vb3r17B7tqUp2dneXl5cSBFakFCxZs3769oqJi9+7d8uVD29Dd3d0pKSnu7u6enp46Ojp79uxhMBiD7YHY2FhjY+Po6GiEEHE/Wv7UGyHEYDC6urooZlHXT9wZ19fXj4mJKSkpqa2tdXNz27p16zfffEM0PDAwMCUlRdnHra2tEULK3tn9JnhD8yORGYnzX2VKSko6Ojpmz54tK5kzZw6TySROJBUwmUyEkEQiQQht3LhRKBTKLtykp6e7ubkR75Ufms7OThzHh1ODzKAapbrZs2dzuVzinFRT6urqcBynfo1fdHT01KlTk5OT8/PzZYVD29BPnjwRi8V2dnZEOYfDMTIyGlQPXLhwISMj47vvvuPz+Qgh4pqpVCqVX6anp4fD4VDMol4FcZl7+vTpTk5Oenp6QqFw//79QqGQSP1hYWGbNm0yMTFR9nGiM2tra1Vv1DjzhubHyZMns9ls4ixbmZaWFtTvGFNHR2fA4zhtbe1NmzYVFBT861//QggdO3ZsmC8RJuK0sbEZTiWEITdqQCwWizhH05Tu7m70R0ZQhs1mp6WlYRj2wQcfyA6+htYnnZ2dCKE9e/bIhqxWVlZS/8eVd/bs2U8//TQvL2/y5MlECXHRljizIYjF4u7ubmNjY4pZ1GshFmhoaJCVMJlMMzOzsrKy/Pz84uLijRs3UnycyL9Ex76Z3tD8yGKx/vKXvzQ0NPzyyy/95zY1NW3cuFFHRwchpPAlaWlpMTU1HbD+gIAABoORkJDw008/TZo0ieKkTxVXr15FCK1YsWI4lRCG0ygKEolk+JUME/FlHnBU84IFC3bs2FFaWnrgwAGiZGh9QtzQULisrOLPCo4cOZKenv7DDz+89dZbskJzc3M+n19ZWSkrefbsGUJoxowZFLOoV6StrW1tbf3w4UP5QqlUKhQKU1NTr1+/TqPRiORONCcmJgbDsLt37xJL9vT0oD869s30huZHhFBkZCSLxdqxY0f/izgPHjyg0+l2dnba2tqyfQUhdPv27Z6enlmzZg1Yuamp6Zo1a7Kysvbu3RsYGDicOGtqahISEkxNTYdzBVOGulF0Op24RDBYeXl5OI4TT5AeciXDZGBggGFYa2vrgEseOHDAxsbm/v37xOTQNvSkSZPYbHZhYeGggsRxPCQkpLi4ODs7W+GIlU6nr1y58qeffurr6yNKcnNzMQxzdXWlmDXgGn18fO7fv//8+XNiUiwWV1ZW2tvbp6WlyWd2+fszsksNRGcaGhoOqo3jyZubHx0cHE6fPv3gwYPFixdfuXKltbVVIpGUl5d/8cUXH374IYPBYLPZQUFBFy5cSE9Pb2trKy4u3rx5s7Gxsb+/vyr1BwUFSaXS5ubmt99+W/WocBzv6Oggbi/W19efO3du4cKFWlpa2dnZarn+SN0oKyurpqam7OxsiURSX18vf8Cip6f38uXLioqK9vZ2Iv0RP/KRSqVFRUWBgYEikYgYh6R6Jbm5uWoc38Plci0sLIg3MQzYCWlpabLbHUPb0Gw2e8OGDWfOnElJSWlra+vt7a2urv79998RQr6+voaGhqQ/W3z48OFnn332xRdfMBgM+Z+THj58GCG0d+/e2traffv2dXZ23rx5My4uzs/Pb+rUqdSzKFaHENqxY4eZmZmfn19VVVVjY2NISEhXV5fCHSpliM6kGDs5/o3ObfLRNKjfolVVVe3cudPe3l5bW1tLS0tHR+e//uu/Pvzww19++QXH8b6+vri4OGtrawaDoaur6+7u/uTJExzHk5OTiUvX1tbWZWVlJ06cIJKXmZnZ06dPZZUvW7bs5MmT8qu7efPmwoULZZeNjIyMnJycbty4cfHixRkzZnC5XCaTSaPREEIYhuno6MydOzcqKqqxsVGVtqg4xkJZo3Acb2xsXLZsGZvNNjc3/+STT4KDgxFCVlZWVVVV9+7dMzMz43A4ixYtqqmp8ff3ZzAYJiYmdDpdIBC4ubmVlZUNtpIrV67w+fzo6OgBY1ZxmxKXNcRiMTF54cIF4srGxIkTt27dqrBwcHCwbHzP0Db0q1evQkJCRCIRnU7X19f39PQsKSnBcdzd3R0hFBER0T9CZfeCZWN3bty4MXfuXBaLZWxsHBwc3N3dLfusslkUqyO8ePFi7dq1urq6LBZr7ty5ubm5/ZchHd/j4uJiYmIiGwxEYbyO73nT8+N4Mpr7qL+/v56e3uisC1d5m5aWltLp9FOnTo1CSBR6e3sXL16cmpr6Wq+uoaGBzWYfPnxYlYXHa358c8+vwTCNwee7WFlZRUVFRUVFyT8RZ5T19vZmZ2e3t7f7+vq+1quLjIx0cHAY5tCL1x3kRzCuhIaGent7+/r6qnKjZiTk5eWdP38+NzeXeiTmGF9dfHx8YWHhlStXGAyGGqt97UB+BIMWFhaWlpbW2tpqbm6elZWl6XAUxcTEBAQEHDx4UCNrd3Z2Pn36tOwX6K/j6nJycl69epWXl6erq6vGal9H4/b9rmDkxMbGxsbGajoKKsuXLyce2AWGYPXq1atXr9Z0FGMCHD8CAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAALlxe/9a9qaON804bvg4bto44OXlpekQ1A/Dx93LJaqrqwsKCjQdBRgKHx+fwMDABQsWaDoQMGiTJk0afxtuHOZH8PrCMOzcuXPEK08B0Di4/ggAAOQgPwIAADnIjwAAQA7yIwAAkIP8CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAADnIjwAAQA7yIwAAkIP8CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAADnIjwAAQA7yIwAAkIP8CAAA5CA/AgAAOciPAABADvIjAACQo2s6APBGq6ys7O3tlS+pra19/vy5bPKtt95is9mjHhcACCGE4Tiu6RjAm8vFxeXKlSvK5jIYjNraWl1d3dEMCQAZOL8GmuTr66tsFo1GW758OSRHoEGQH4EmeXh4KDt9xnH8vffeG+V4AJAH+RFoEo/He/fddxkMRv9ZLBbr3XffHf2QAJCB/Ag0bN26dVKpVKGQwWB4eHjweDyNhAQAAfIj0LCVK1dqa2srFEokknXr1mkkHgBkID8CDWMymd7e3kwmU75QIBC88847mgoJAALkR6B5f/vb33p6emSTDAZj7dq1ChkTgNEH4x+B5vX19RkZGdXX18tKbty48ac//UmDIQGA4PgRjAU0Gm3dunWyu9j6+vqLFi3SbEgAIMiPYIxYu3atRCJBCDGZTD8/PxoN9kygeXB+DcYEHMcnT55cVVWFELp79+6sWbM0HREAcPwIxgYMw95//32EkIWFBSRHMEb8x/N7bt68GR8fr6lQwBuura0NIcRms729vTUdC3hDLViwYMeOHbLJ/zh+fPHiRVZW1qiHBABCCAkEAh0dnaamplu3bmk6lhFRXV0N36+x7NatWzdv3pQvIXn+Y2Zm5mjFA8B/uHbt2j/+8Q80TnfCjIwMHx+fcdm08aH/iQtcfwRjCPxmBowpkB8BAIAc5EcAACAH+REAAMhBfgQAAHLqzI+HDx82MDDAMOz48ePUS86ZM0dLS8vBwWEkKgf99e+9K1euCIXCb7/9dviV9/X1JSQkODk5KVtg48aNfD4fw7DCwsLhr64/NbZlTLl27VpoaOj58+ctLCwwDMMwTOGFE8uXL+fz+VpaWtOnT793795oxhYVFWVraysQCFgslpWV1a5duzo6OmRz8/PzFy5cyOVyjY2NQ0JCXr16pcosahKJJDY21srKislk6ujo2NnZVVRUKCzT3d1tY2OzZ88ehNDFixcPHTqk8HbMwVJnfty5c2dBQYEqS965c2fZsmUjVDnor3/vqet3paWlpX/605927NghFouVLXPy5MkvvvhCLasjNS5/I7tv376kpKSwsDBPT8/nz59bWlpOmDAhPT398uXLsmW+//77zMzMVatWlZSUODo6jmZ4P/zww9atWysqKhoaGmJjYxMTE2WDY0pKSpYvX+7s7FxfX3/hwoUvv/xy8+bNA84akI+Pz9dff3369GmxWPzo0SNLS0v5jEwIDw9/8uQJ8berqyubzXZ2dm5paRlyMzV5fo1hmAbX/oZzcXFpbW1dtWrVcCr597//vXv37s2bNw/qVEDt1NIWCl1dXRRHxyPh008/PXv2bEZGBp/PlxUmJSXRaDR/f//W1tbRDIaUtra2v7+/np4en89fs2aNu7tAvYgXAAAgAElEQVT71atXX7x4gRA6cOCAkZHR/v37eTzeggULQkJCvvrqq8ePH1PPonb27Nns7OzMzMx58+bR6XRjY+OcnBw7Ozv5ZQoKCh48eCBfsm3btpkzZ65cubL/CzxUpIb8iON4ZmbmiRMnBvtB0rcyjRtD7pYxTr5dM2fOPH/+/Lp161gsFvWnXuv/hampqXV1daO2umfPnu3du3f//v0Kb3Z0cnIKDAz87bffdu7cOWrBKHPp0iUtLS3Z5MSJExFCYrFYKpVevnx5yZIlsi2+YsUKHMdzcnIoZg24umPHjjk6Otrb2ytboKurKzg4ODExUaE8MjKysLCwf7mKhpIfe3t7Y2Njp06dyuFwJk6caG5uHhsbu2bNmv5L4jgeHx8/bdo0Foulq6vr5uYm/7/i2bNnNjY2PB6Pw+EsXrw4Pz+fKP/5559tbW2FQiGbzba3t//uu+8GGyFpDdOmTcMwjEajzZo1izgZ3LVrF7HMV1991dvbGxERIRKJOBzOjBkzzp07hxD67LPPuFwun8+vq6sLCgoyMTF58uSJsvAouoW0cgpJSUlsNtvAwOCjjz4yNjZms9lOTk63b98esFepO1wmPz9fJBJhGHb06FGEUEpKCo/H43K5OTk5K1asEAgEpqamZ86cGbBdFHAcj4uLmzp1KovFEgqFwcHBKm25wVO9LRS9GhAQwGQyjYyMiDq3bNnC4/EwDGtoaAgMDAwKCiorK8MwzMrKCiF09epVgUAQExMzQi1KSkrCcdzV1bX/rOjo6ClTppw8efLatWv95yrb+gNu30HtnKR+++03Dodjbm7+/Pnzjo4OkUgkm2VpaYkQKioqophFXXlPT8+tW7eoz1HCw8O3bNmir6+vUK6rq7tkyZLExMQhXoTB5RBdgw8kJiZGS0srJydHLBb/+uuvhoaGS5cuJWaVlpYihI4dO0ZMRkREMJnMU6dOtbS0FBUVOTo6Tpw4saamBsdxZ2dnCwuL8vJyiUTy4MGDefPmsdnsp0+fEocnkZGRTU1NjY2N8+fPnzBhAmnlFEhrkEqlkydPFolEUqlUtuT27dsTEhJwHN+5cyeLxcrKympubg4LC6PRaHfu3MFxPDw8HCG0bdu2I0eOeHh4PHr0SFl4FN2irHIK/v7+PB7v4cOH3d3dJSUlc+bM4fP5VVVV1L1KMUuh94hToSNHjhCTRDOvX7/e2tpaV1e3ePFiHo/X09ND3S6ZefPmzZw5U74kPDwcw7DPP/+8ublZLBYnJycjhO7fvz/gtvPy8vLy8hpwMXmqt4WiV9etW2doaCirMy4uDiFUX1+P47inp6elpaVs1qVLl/h8flRU1KCCxFX+fllYWNja2ioUWlpalpeX4zheUFBAo9EmT57c0dGB43hubu7q1auJZSi2PkWfDGHnVNDZ2cnn8wMCAnAcv3HjBkIoLi5OfgEOh+Ps7Ewxi7r+8vJyhJCDg8PSpUuNjIxYLJaNjc3Ro0f7+vqIBfLz811dXXEcJx5BHx4eLv/x0NDQIe97Q8mPc+bMmTt3rmxy06ZNNBrt1atX+H9+CcVisba2tq+vr2zJf/3rXwghYsdydnaW/0YR/0N27typsK7Y2FiEUF1dHT6Y/KishoSEBIRQRkYGMauzs1MkErW2tnZ1dXG5XFmoYrGYxWJ9/PHH+B87VldX14CVK+sWisop+Pv7C4VC2eSdO3cQQvv376foVeoOVyU/yppJpLNnz55RtEs+WoX8KBaLuVzun//8Z1kJcbQymvmRtC3KehUfTH4cMlW+Xx0dHRiGrVq1SqFclh9xHA8KCkIIbd26FZfLj9RbX1mfDG3nVBAeHj5lypS2tjYcx7///nuEUHx8vPwCAoHAycmJYhZ1/cXFxQihP//5z7/88ktjY2NLS8vu3bsRQunp6UTMs2fPrq6uxpXkxy+//BIh9PXXXw/YkP773lDOr7u7u3G5g9Xe3l4GgyF/MYJQUlLS0dExe/ZsWcmcOXOYTKbsPFGevb29UCjsf6RNXKMczk16+Ro2btwoFAplFyPS09Pd3NwEAsGTJ0/EYrHsci+HwzEyMlLlsrF85cq6ZciVy5s9ezaXy338+DFFrw6qw6kR78YiHuit4uaW9+zZM7FY7OzsPNj1jgT5tiiQ9eqoB6UU8b+Wy+VSLBMdHT116tTk5GTZJSk0yK+brE+Gv3NeuHAhIyPju+++I24lEddMFe6H9PT0cDgcilnUqyCubk+fPt3JyUlPT08oFO7fv18oFBIXwcPCwjZt2mRiYqLs40Rn1tbWqt4omaHkx5UrV/766685OTldXV13797Nzs5+9913+39hiNvqCq821tHRaW9vJ62WwWAQO/Hly5eXLl2qr6/PYrF27do1hAiV1aCtrb1p06aCggLiX+uxY8cCAgIQQp2dnQihPXv2YH+orKxUNmBFWeXKumVQlVNgsVj19fUUvTrYDleRiptbXnV1NUKo/8WgMYjoVU1H8X+6u7vRHxlBGTabnZaWhmHYBx980NXVRRQObesPc+c8e/bsp59+mpeXN3nyZKKEuIZLPMqTIBaLu7u7jY2NKWZRr4VYoKGhQVbCZDLNzMzKysry8/OLi4s3btxI8XEi/xIdO1hDyY+RkZFvv/22n5+fQCDw8PBYs2YN6eg2HR0dhJDC5mlpaTE1Ne2/sFQqbWpqEolEVVVV7u7uRkZGt2/fbm1tPXTo0GDDo64hICCAwWAkJCT89NNPkyZNIq4QE99k4kKkjMKT4AasXFm3qF45BYlEQnQdRa8OqsNVp+LmlkccKag+9FdTZL2q6UD+D/FlHvCEiXiMa2lp6YEDB4iSoW394eycR44cSU9P/+GHH9566y1Zobm5OZ/Pr6yslJU8e/YMITRjxgyKWdQr0tbWtra2fvjwoXyhVCoVCoWpqanXr1+n0WhEcieaExMTg2HY3bt3iSWJVwcPeJRKiuT5jwMqKSkpKyurr6+n06k+bmdnp62tLYsSIXT79u2enh7Sp+f/+OOPfX19jo6OxcXFEonk448/trCwQEMaF0Jdg6mp6Zo1a86dO/fy5ct9+/YRhZMmTWKz2ar8uoOicmXdonrlFPLy8nAcnz9/PkWvDqrDVafi5pZnZ2dHo9Fu3Lih+uhfjZD1KkKITqeTnoOPMuJnTqqMcDxw4MClS5fu379P3BEe2tYf2s6J4/ju3bubm5uzs7MV9go6nb5y5cqffvqpr6+PeMlabm4uhmGurq4UswZco4+PT0xMzPPnz4nvnVgsrqysfPfdd9PS0tLS0mSLNTQ06Ovrh4eHR0dHywqJzjQ0NBxUGwlDOX7cunWrSCTqP3hdAZvNDgoKunDhQnp6eltbW3Fx8ebNm42Njf39/YkFenp6WltbpVLpvXv3AgICzMzM/Pz8iI197dq17u7u0tLSIVw7G7CGoKAgqVTa3Nz89ttvy0LdsGHDmTNnUlJS2traent7q6urf//990FVrqxbVK9cQV9fX3Nzs1QqLSoqCgwMFIlEfn5+FL06YIcPjYqbW56+vr6Xl1dWVlZqampbW1tRUdHYGQdK2qsIISsrq6ampuzsbIlEUl9fL3+Yo6en9/Lly4qKivb2dolEkpubO3Lje7hcroWFBXGBghpxli270DG0rU+xc/r6+hoaGpL+bPHhw4efffbZF198wWAwMDmHDx9GCO3du7e2tnbfvn2dnZ03b96Mi4vz8/ObOnUq9SyK1SGEduzYQeSHqqqqxsbGkJCQrq4u4i7NgIjOpBg7SUX+uFrF+9c//PDDhAkTZDUwGIxp06adP3/+888/J5I0j8fz8PDAcbyvry8uLs7a2prBYOjq6rq7uz958oSoJC0tbdmyZQYGBnQ6fcKECWvXrq2srCRmhYSE6Onp6ejoeHt7E4PaLC0tAwMDFSqnQFoDMYyDsGzZspMnT8p/5NWrVyEhISKRiE6n6+vre3p6lpSUHDp0iDgsnzRp0qlTp6grV9YtyiqnboK/vz+DwTAxMaHT6QKBwM3NraysjJhF0avKZilsmiNHjhAXg7hcrqura3JyMnEN29rauqys7MSJEwKBACFkZmb29OlTinbdvHlz4cKFsutHRkZGTk5ON27cwHG8vb39//2//zdhwgRtbe1FixZFREQghExNTf/9739TN3yw968H1RaKXm1sbFy2bBmbzTY3N//kk0+IAZtWVlZVVVX37t0zMzPjcDiLFi2qqam5cuUKn8+Pjo5WPUiCit8v4hKQWCwmJi9cuEBcBZo4cSJxz1pecHCwbHyPsq1P3SfKdk53d3eEUERERP8IiRvK/cnG7ty4cWPu3LksFsvY2Dg4OJi4xUc9i2J1hBcvXqxdu1ZXV5fFYs2dOzc3N7f/MqT3r11cXExMTGSDgSioZ3xPcnJyYGCgbPLVq1fbt29nsViyLfpmUm+3ED/eUl90QzfKm3sI43tUp9leVfH7VVpaSqfTZf+PNaW3t3fx4sWpqamv9eoaGhrYbPbhw4dVWbj/vjfo6481NTUBAQHyFyyYTKZIJJJIJBKJZGgXQceBkeiWYT56RC3G3+YeC71KzcrKKioqKioqys3NTeF+9Kjp7e3Nyclpb2/39fV9rVcXGRnp4OBADFMZgkFff+RwOAwGIzU1tba2ViKRvHz58uTJkxEREb6+vsRB+yh4/PgxptzobFEFg+2WMdgEUmNhc7+BQkNDvb29fX19NfUoiry8vPPnz+fm5lKPxBzjq4uPjy8sLLxy5crQH/UgfzCp4vH/Tz/99M477wgEAi0tLaFQ6OTklJycLJFIBnXcO/6osVtCQ0OJEbyTJ0/OzMxUe6iDMsqbe+TOrzXeqyp+v2S+++67kJCQkYtnfMvOzo6NjZX/MfGA+u97GC730wji/ZP4eHyaHnhdEI8RHJcvQYXv1xjXf9+D9ysAAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAADmS8eGv9atCwPgwjnfCcdy0ccDLy0t+kiQ/Du0FFACoBfGM9+3bt2s6EPW7efNmYmIifL/GLGLfk0eSHwd89RIAI4cYfTZed8LExMTx2rRxoP+oW7j+CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADk1JAfnz59+sknn0yfPl0gEDCZTH19fRsbGw8Pj//5n/9BCB0+fJh45dDx48ep65kzZ46WlpaDg4Pqq6au/JtvvsEwzMnJaVDNGWXnz5+3sLCQPfmRePr/unXrHj16NOQ6+3fLlStXhELht99+O/yA+/r6EhIS5HtVoQkYhjGZTAMDg6VLl8bFxTU3Nw9/pWBQrl27FhoaKr9d3nvvPfkFli9fzufztbS0pk+fruyVLyNHIpHExsZaWVkxmUwdHR07O7uKigqFZbq7u21sbPbs2YMQunjx4qFDhzTzYGP5h50N9vl0OI6npaUxmcxFixZdvXq1ubm5u7u7rKzs22+/dXFx8ff3J5YpLS1FCB07dmzA2pydnWfOnDmoACgqd3FxIV7cUVpaOqg6R5+lpaVQKMRxvKOj4+LFiyKRSFtb+/Hjx0OuUKFbLl26JBAILl68OMw4nz59unDhQoRQ/80kawLxAqwff/zRz88PwzBjY+M7d+6ovooRfb+CZg3h+zUEERERq1atamtrIyYtLS2J1wddunRJfrHc3FzZi2tGmbu7+9SpU2/dukU8cdnV1bW4uFhhmR07diC5N8kkJiYuWbKkubl5RAPrv+8N6/jx1q1bGzdudHJy+vHHH//yl7/o6OiwWCwLC4t33303KSlpaHWq69cFjY2NDx8+3L9/P0Lo66+/Vkudo4DH461ateq///u/Ozo6jhw5oq5qXVxcWltbV61aNZxK/v3vf+/evXvz5s3Ux/gYhuno6CxdujQtLS0jI6O2tpZY+3BWrS5dXV3DP59QSyUj5NNPPz179mxGRgafz5cVJiUl0Wg0f3//sbAVzp49m52dnZmZOW/ePDqdbmxsnJOTY2dnJ79MQUHBgwcP5Eu2bds2c+bMlStXSqXS0Yx2WPkxJiamt7f34MGD/d+MbGFhMeAJNamhPwn9P2VkZLi4uLi6urLZbOJVR2qpdrBwHM/MzBzs203nzp2LEFLYRTRCPv6ZM2eeP39+3bp1LBZLxY97eXn5+fnV1dUNbWdQu9TU1Lq6urFQyUh49uzZ3r179+/fz2az5cudnJwCAwN/++23nTt3aio2mWPHjjk6OlK8bbWrqys4ODgxMVGhPDIysrCwsH/5iBp6fuzp6bl27Zqenh7xenXV4TgeHx8/bdo0Foulq6vr5ub2+PFj2dxnz57Z2NjweDwOh7N48eL8/Hyi/Oeff7a1tRUKhWw2297e/rvvvqNeyzfffOPh4cHn85cvX15RUfHzzz8T5dOmTcMwjEajzZo1SywWI4R27dpFVPvVV1/19vZGRESIRCIOhzNjxgzihOizzz7jcrl8Pr+uri4oKMjExOTJkyfK4unt7Y2NjZ06dSqHw5k4caK5uXlsbCzxkwnSykkR/ySJNETRXdQ9KZOfny8SiTAMI95Gm5KSwuPxuFxuTk7OihUrBAKBqanpmTNnBox/aIi3S+fm5g65BlLK2h4QEMBkMok3viKEtmzZwuPxMAxraGgIDAwMCgoqKyvDMMzKyiopKYnNZhsYGHz00UfGxsZsNtvJyYl4obnqlSCErl69OnKvwx6UpKQkHMddXV37z4qOjp4yZcrJkyevXbvWf66yzhxwV1Fxf5bp6em5desW9flHeHj4li1b9PX1Fcp1dXWXLFmSmJg4qsc68ifbg7o+8vTpU4TQ/PnzB1xS4VpYREQEk8k8depUS0tLUVGRo6PjxIkTa2pqcBx3dna2sLAoLy+XSCQPHjyYN28em81++vQpcRQTGRnZ1NTU2Ng4f/78CRMmkFZOqKys1NfXJ149cerUKYTQhx9+SMySSqWTJ08WiUTyL6bYvn17QkICjuM7d+5ksVhZWVnNzc1hYWE0Go24dhYeHo4Q2rZt25EjRzw8PB49eqQsnpiYGC0trZycHLFY/OuvvxoaGi5dupSYpaxyXO7iHYGIOTg4mLq7KGYpdMuLFy8QQkeOHCEmieZcv369tbW1rq5u8eLFPB6vp6eHOn6ZefPmUVx/VNDW1oYQmjRpkpK9Q5GK1x8p2r5u3TpDQ0PZknFxcQih+vp6HMc9PT0tLS1ls/z9/Xk83sOHD7u7u0tKSubMmcPn84n3pKteyaVLl/h8flRU1IAxj/T1RwsLC1tbW4VCS0vL8vJyHMcLCgpoNNrkyZM7Ojrw/7z+SNGZFLsKxf6sTHl5OULIwcFh6dKlRkZGLBbLxsbm6NGjspdT5+fnu7q64kreZB0aGooQun///rC7ipx63n9NuHv3LkLonXfeGXBJ+e+qWCzW1tb29fWVzf3Xv/6FECJ2L4X7M0VFRQihnTt3KlQYGxuLEKqrq8OV5MeDBw9u2LCB+Lu1tZXFYgkEAtn7molfoWdkZBCTnZ2dIpGotbW1q6uLy+XKYhOLxSwW6+OPP8b/2Eu6urpIGygfz5w5c+bOnSubtWnTJhqN9urVK4rK8f+8P5OVlWVoaGhgYFBdXU3RXdQ9qUp+lDUnOTkZIfTs2TOK+OXbO6j8iOM4cUWSdFZ/quRH6rYPKj/Kx3znzh2E0P79+wdViepGND92dHRgGLZq1SqFcll+xHE8KCgIIbR161ZcLj9Sd6ayXYV6f1amuLgYIfTnP//5l19+aWxsbGlp2b17N0IoPT2dqGT27NnV1dW4kvz45ZdfIoS+/vrroXXRgNR5f4Z4M29nZ6dCeUZGhrm5OTGqYNq0aQpXakpKSjo6OmbPni0rmTNnDpPJJM5rFNjb2wuFQiJLyiOuUVLc7ydOrom/BQLB8uXL29racnJyiJKNGzcKhULZhYz09HQ3NzeBQPDkyROxWCy7VMzhcIyMjEjPWCni6e7uxuWO/3t7exkMhpaW1oCVt7a2YhgmFAq3bdu2cuXKf/3rXyYmJhTdNaiepEa81U8ikVDEP9g6ZTo7O3EcV+/LYNXYdnmzZ8/mcrmqbPExiPj3TP1+1Ojo6KlTpyYnJ8suW6FBdqZsVxnal4W4ZDR9+nQnJyc9PT2hULh//36hUEhc4A4LC9u0aZOJiYmyjxOtq62tpV6LGg09P5qZmbFYrGfPnimUr1mzpry83MzMzNDQ8NGjRwYGBvJzW1pa0B+5VUZHR6e9vZ10LQwGg/jeXr58eenSpfr6+iwWa9euXRSBPXjwoLi4eNWqVbLheMS4P9ldbG1t7U2bNhUUFBD/J48dO0a8PpzI9Xv27JF9sLKykrhG2Z+yeFauXPnrr7/m5OR0dXXdvXs3Ozv73Xff1dLSGrBy4kBGKpVWV1d/+eWXZmZm1N012J5UkbL4h1whcR3GxsZmOFEpGKG2I4RYLBZx5PLa6e7uRn8kIGXYbHZaWhqGYR988EFXVxdROLTOHNSXRcbY2Bgh1NDQICthMplmZmZlZWX5+fnFxcUbN26k+DiHw0F/tHR0DD0/stnsd955p76+/tatW6p/SkdHByGk0PUtLS2mpqb9F5ZKpU1NTSKRqKqqyt3d3cjI6Pbt262trYcOHaJYxenTp9euXSt/kNzU1MThcL7//vuamhpimYCAAAaDkZCQ8NNPP02aNIkYJklcEiYuRMrcvHmz/yoo4omMjHz77bf9/PwEAoGHh8eaNWu++OKLQVWuYncNqidVpyz+Ibt69SpCaMWKFcOpRMEItV0ikQy/Ek0hcseAg6gXLFiwY8eO0tLSAwcOECVD68yh7c/a2trW1tYPHz6UL5RKpUKhMDU19fr16zQajci2RP0xMTEYhhGX8hBCPT09spaOjmGN79m/fz+DwQgODiYO8VRhZ2enra0tazBC6Pbt2z09PbNmzeq/8I8//tjX1+fo6FhcXCyRSD7++GMLCws2m00xRhLH8bNnz27ZskW+UFdX19vbu7e395tvviFKTE1N16xZk5WVtXfv3sDAQKJw0qRJbDa7sLBwwFZQxFNSUlJWVlZfXy+RSKqqqlJSUnR1dQdVuTyK7hpUT6pOWfxDU1NTk5CQYGpq+sEHHwwnKgXUbafT6arvkPLy8vJwHCfGYwy5Ek0hfjGlygjHAwcO2NjY3L9/n5gc2o40tP0ZIeTj43P//v3nz58Tk2KxuLKy0t7ePi0tTT7Vyl9/lJ37E60zNDQc7EqHbFj5cdasWadOnfr111+XLl169erV33//XSqVVlZWnjp1qqmpifQjbDY7KCjowoUL6enpbW1txcXFmzdvNjY29vf3Jxbo6elpbW2VSqX37t0LCAgwMzPz8/MTiUQIoWvXrnV3d5eWllJcZiooKBAIBMRvPORt3rwZ/edA8aCgIKlU2tzc/Pbbb8ti27Bhw5kzZ1JSUtra2np7e6urq3///ff+a6GIZ+vWrSKRqKOjo3/DVaxcxe4asCeHRln8qsBxvKOjg7gXWV9ff+7cuYULF2ppaWVnZ6v3+iN1262srJqamrKzsyUSSX19fWVlpeyDenp6L1++rKioaG9vJ9If8WsfqVRaVFQUGBgoEomIAUmqV5KbmzsWxvdwuVwLC4vq6uoBlyTOsmXXTIa2I1Hsz76+voaGhsp+trhjxw7iS11VVdXY2BgSEtLV1UXcpRkQ0TqKsZPqJ5+zh3Z/rby8PDAwcPr06Twej81mm5ubL168ePfu3T/99BOO459//jmR73k8noeHB47jfX19cXFx1tbWDAZDV1fX3d39yZMnRFVpaWnLli0zMDCg0+kTJkxYu3ZtZWUlMSskJERPT09HR8fb25sYx2dpaRkYGChf+Ycffsjj8eh0+syZM+/duyeL8MCBA8SFD4SQiYlJcnIyUb5s2bKTJ0/Kt+XVq1chISEikYhOp+vr63t6epaUlBw6dIg4pJ80aRIx1FxZPFVVVT/88APxcy4Cg8GYNm3a+fPnlVX+yy+/TJkyhVjY2NjY29tboXspukvZLIU+P3LkCDGUj8vlurq6JicnE9e5ra2ty8rKTpw4QSQvMzOzp0+fUsR/8+bNhQsXynrSyMjIycnpxo0bFy9enDFjBpfLZTKZNBoN/fETmrlz50ZFRTU2Ng5qd1JxfA9FtzQ2Ni5btozYFT/55JPg4GCEkJWVVVVV1b1798zMzDgczqJFi2pqavz9/YkfvNPpdIFA4ObmVlZWNthKrly5wufzo6OjB4x5pMf3EFeNZOM0Lly4QFw4mjhxInHPWl5wcLBsfI+yzqTeVUj3ZxzH3d3dEUIRERHK4nzx4sXatWt1dXVZLNbcuXNzc3P7L0N6/9rFxcXExEQ2GEjt1Dm+B5BKTk4ODAyUTb569Wr79u0sFku2145xGo9/NH9/7e/vr6enNzrrwkf++1VaWkqn02X/wjWlt7d38eLFqamp6q22oaGBzWYfPnxYvdXK67/vkbx/BgxZTU1NQECA/EUZJpMpEokkEolEIhnN68pD87rHPwSaeSrMyLCysoqKioqKinJzc1O4Hz1qent7c3Jy2tvbfX191VtzZGSkg4MDMdRk1MDzH9WJw+EwGIzU1NTa2lri2SQnT56MiIjw9fVV7wW4EfK6xw9CQ0O9vb19fX019SiKvLy88+fP5+bmUo/EHKz4+PjCwsIrV66o6/kMKoL8qE5CofD7779/8ODBlClTOByOra1tWlrap59++s9//lPToankdY9/UMLCwtLS0lpbW83NzbOysjQdjtrExMQEBAQcPHhQI2t3dnY+ffq07KfrapGTk/Pq1au8vLzhDKUYGgyX+7FERkaGj48PrqFH3QCAEPL29kZkb9ocB+D7Ncb13/fg+BEAAMhBfgQAAHKQHwEAgBzkRwAAIEcy/jEjI2P04wCAQPyGbFzuhMTjG8Zl08aH6upqxadyyA8WV+UJ6QAAMF4p/H4Gg9EGYOzAMOzcuXPDed0NAGoE1x8BAIAc5EcAACAH+REAAMhBfitmVjkAACAASURBVAQAAHKQHwEAgBzkRwAAIAf5EQAAyEF+BAAAcpAfAQCAHORHAAAgB/kRAADIQX4EAABykB8BAIAc5EcAACAH+REAAMhBfgQAAHKQHwEAgBzkRwAAIAf5EQAAyEF+BAAAcpAfAQCAHORHAAAgB/kRAADIQX4EAABykB8BAIAc5EcAACAH+REAAMhBfgQAAHKQHwEAgBzkRwAAIAf5EQAAyEF+BAAAcpAfAQCAHF3TAYA32hdffNHU1CRfkpOTU15eLpvcsGGDgYHBqMcFAEIIYTiOazoG8Ob66KOP/vGPf7BYrP6zJBKJrq5uTU0NnQ7/xYFmwPk10KS1a9cihF6R0dLS+tvf/gbJEWgQHD8CTcJx3MTE5PfffyedW1BQsGDBglEOCQAZOH4EmoRh2Lp165hMZv9Zb7311vz580c/JABkID8CDVu7dm1PT49CIZPJ/Pvf/45hmEZCAoAA59dA86ytrZ89e6ZQWFRUZG9vr5F4ACDA8SPQvPXr1zMYDPkSKysrSI5A4yA/As1bv369VCqVTTIYjA0bNmgwHgAIcH4NxgQHB4eioiJib8QwrKyszNzcXNNBgTcdHD+CMeH999/X0tJCCGEYNmvWLEiOYCyA/AjGhLVr1/b19SGEtLS03n//fU2HAwBCkB/BGGFsbLxw4UIMw/r6+ry9vTUdDgAIQX4EY8d7772H4/jSpUuNjIw0HQsACMH9GQoZGRk+Pj6ajgKAkeXl5ZWZmanpKMYo+PH/AM6dO6fpENTs5s2biYmJY7NdCQkJmzZt4vF4Q67Bx8cnMDAQfrWtooSEBE2HMKZBfhzAmjVrNB2C+iUmJo7Ndi1atOitt94aTg0+Pj4LFiwYm60bg+DIkRpcfwRjyDCTIwDqBfkRAADIQX4EAABykB8BAIAc5EcAACAH+VFtXr16tW3bNiMjIy6X+8477xgYGGAYdvz4cU3HpR5XrlwRCoXffvutpgNRp2vXroWGhp4/f97CwgLDMAzD3nvvPfkFli9fzufztbS0pk+ffu/evVEOTyKRxMbGWllZMZlMHR0dOzu7iooKhWW6u7ttbGz27NmDELp48eKhQ4d6e3tHOc5xDPKj2nz++edXr159/PhxYmLiRx99VFBQoOmI1Gn8/Y5g3759SUlJYWFhnp6ez58/t7S0nDBhQnp6+uXLl2XLfP/995mZmatWrSopKXF0dBzlCH18fL7++uvTp0+LxeJHjx5ZWlp2dHQoLBMeHv7kyRPib1dXVzab7ezs3NLSMsqhjleQH9UmOzt79uzZOjo6mzZt8vLyUvFTXV1dTk5OyibHDhcXl9bW1lWrVo1Q/aPc8E8//fTs2bMZGRl8Pl9WmJSURKPR/P39W1tbRy0SZc6ePZudnZ2ZmTlv3jw6nW5sbJyTk2NnZye/TEFBwYMHD+RLtm3bNnPmzJUrV8o/TxMMGeRHtamurlZ4CLYqUlNT6+rqlE2+OUaz4c+ePdu7d+/+/fvZbLZ8uZOTU2Bg4G+//bZz587RiYTCsWPHHB0dKR6i3tXVFRwcnJiYqFAeGRlZWFjYvxwMAeRHNfjf//1fKyur33///Z///CeGYdra2v2X+fnnn21tbYVCIZvNtre3/+677xBCgYGBQUFBZWVlGIZZWVkpTCKEent7IyIiRCIRh8OZMWMG8aPAlJQUHo/H5XJzcnJWrFghEAhMTU3PnDkzcg3Mz88XiUQYhh09epQ6gKSkJDabbWBg8NFHHxkbG7PZbCcnp9u3byOEAgICmEym7NkTW7Zs4fF4GIY1NDT0b/jVq1cFAkFMTMxINCcpKQnHcVdX1/6zoqOjp0yZcvLkyWvXrvWfi+N4fHz8tGnTWCyWrq6um5vb48ePqTsEKdmI1Hp6em7duuXg4ECxTHh4+JYtW/T19RXKdXV1lyxZkpiYOP4uiWgADpQg9mPVlzc0NPz73/8umywtLUUIHTt2jJjMzMyMjIxsampqbGycP3/+hAkTiHJPT09LS0vZpxQmd+7cyWKxsrKympubw8LCaDTanTt3cBwPDw9HCF2/fr21tbWurm7x4sU8Hq+np2ck2kV48eIFQujIkSPEJEUA/v7+PB7v4cOH3d3dJSUlc+bM4fP5VVVVOI6vW7fO0NBQVmdcXBxCqL6+vn/DL126xOfzo6KiBhsnQujcuXPUy1hYWNja2ioUWlpalpeX4zheUFBAo9EmT57c0dGB43hubu7q1auJZSIiIphM5qlTp1paWoqKihwdHSdOnFhTU0PdIco2IoXy8nKEkIODA/E0IxaLZWNjc/To0b6+PmKB/Px8V1dXHMfr6+sRQuHh4fIfDw0NRQjdv39/wO7y8vLy8vIacLE3Fhw/jhIvL699+/bp6urq6em5uro2NjYSezaF7u7ulJQUd3d3T09PHR2dPXv2MBiMtLQ02QJOTk4CgUBfX9/X17ezs7OqqmqEG6FIWQB0Op04yLK1tU1JSWlvb5cPWxUuLi5tbW179+5Ve8ydnZ3l5eWWlpbKFliwYMH27dsrKip2794tX97V1RUfH+/h4bF+/XqhUGhvb3/8+PGGhoYTJ07IlunfIQNuRFLEfRh9ff2YmJiSkpLa2lo3N7etW7d+8803RCSBgYEpKSnKPm5tbY0QKi4uVq1LgFKQHzWAuEw54DiMJ0+eiMVi2SV5DodjZGREnNApYDKZCCGJRKLuSFVFEcDs2bO5XC5p2BpRV1eH4ziXy6VYJjo6eurUqcnJyfn5+bLCkpKSjo6O2bNny0rmzJnDZDKJqwcKZB2i+kaUx2KxEELTp093cnLS09MTCoX79+8XCoVELg4LC9u0aZOJiYmyjxOtq62tpV4LGBDkx1Fy+fLlpUuX6uvrs1isXbt2qfKRzs5OhNCePXuwP1RWVorF4hGOVP1YLNaAB8ujpru7G/2RgJRhs9lpaWkYhn3wwQddXV1EITFoRuHiso6OTnt7O0VVQ9uIxsbGCKGGhgZZCZPJNDMzKysry8/PLy4u3rhxI8XHORwO+qOlYDggP46Gqqoqd3d3IyOj27dvt7a2Hjp0SJVPEZfeExIS5C+I3Lx5c4SDVTOJRNLS0mJqaqrpQP5/RO4Y8OB9wYIFO3bsKC0tPXDgAFGio6ODEFLIhgM2bWgbUVtb29ra+uHDh/KFUqlUKBSmpqZev36dRqMR2ZaoPyYmBsOwu3fvEkv29PTIWgqGA/LjaCguLpZIJB9//LGFhQWbzcYwTJVPTZo0ic1mFxYWjnR4IyovLw/H8fnz5yOE6HS6Bi8CEIjfNakywvHAgQM2Njb3798nJu3s7LS1tWU5CCF0+/btnp6eWbNmUVQy5I3o4+Nz//7958+fE5NisbiystLe3j4tLU0+1crfn5Gd+xOtMzQ0HOxKgQLIj6NBJBIhhK5du9bd3V1aWip/xUpPT+/ly5cVFRXt7e0SiUR+UktLa8OGDWfOnElJSWlra+vt7a2urv7999811w5V9fX1NTc3S6XSoqKiwMBAkUjk5+eHELKysmpqasrOzpZIJPX19ZWVlbKPKPRDbm7uCI3v4XK5FhYW1dXVAy5JnGUTb50lJoOCgi5cuJCent7W1lZcXLx582ZjY2N/f3/qSpRtRF9fX0NDQ2U/W9yxY4eZmZmfn19VVVVjY2NISEhXV5fCLSNliNZRjJ0EqhrpG+SvL9XHwVRUVPzXf/0XQohOpzs6OmZlZX3++efEf28ej+fh4YHjeEhIiJ6eno6Ojre3NzGK0NLSsqqq6t69e2ZmZhwOZ9GiRTU1NQqTr169CgkJEYlEdDpdX1/f09OzpKQkOTmZuABvbW1dVlZ24sQJgUCAEDIzM3v69Kka2yVz5MgRYtwil8t1dXWlDsDf35/BYJiYmNDpdIFA4ObmVlZWRtTT2Ni4bNkyNpttbm7+ySefBAcHI4SsrKz698OVK1f4fH50dPSg4sRVG98TEBDAYDDEYjExeeHCBeJ29sSJE7du3aqwcHBwsGx8T19fX1xcnLW1NYPB0NXVdXd3f/LkCY7j1B1CuhFxHHd3d0cIRUREKIvzxYsXa9eu1dXVZbFYc+fOzc3N7b8M6fgeFxcXExMT2WAgCjC+hxrkR6WGNk5w7Bvpdvn7++vp6Y1c/dRUyY+lpaV0Ov3UqVOjE5Iyvb29ixcvTk1NVW+1DQ0NbDb78OHDqiwM+ZEanF8D9Rvjj5CxsrKKioqKiorq/7iHUdPb25udnd3e3u7r66vemiMjIx0cHAICAtRb7ZsJ8iN4E4WGhnp7e/v6+mrqURR5eXnnz5/Pzc2lHok5WPHx8YWFhVeuXBnCowBAf5AfgTqFhYWlpaW1traam5tnZWVpOhwqMTExAQEBBw8e1MjanZ2dT58+Lfs1ulrk5OS8evUqLy9PV1dXjdW+yeD9rkCdYmNjY2NjNR2FqpYvX758+XJNR6E2q1evXr16taajGFfg+BEAAMhBfgQAAHKQHwEAgBzkRwAAIAf3ZwaQkZGh6RDUjHg4wvhrl8xr9wgPDaqurh47jw4ZgzAcHsKuREZGho+Pj6ajAGBkeXl5ZWZmajqKMQqOHwcw/v5/EHl//LWLgGHYuXPn1qxZo+lAXg/e3t6aDmFMg+uPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJCD/Dgs58+ft7CwwMhMnjz58OHDxNugjh8/rulIAYlr166FhobKb8T33ntPfoHly5fz+XwtLa3p06cre1HMyJFIJLGxsVZWVkwmU0dHx87OrqKiQmGZ7u5uGxubPXv2IIQuXrx46NChMf5w4tcL5Mdh8fT0fP78uaWlpVAoJB7ILpVKxWJxbW0tl8vduXNnQUGBpmME5Pbt25eUlBQWFibbiBMmTEhPT798+bJsme+//z4zM3PVqlUlJSWOjo6jHKGPj8/XX399+vRpsVj86NEjS0vL/g88Dw8Pf/LkCfG3q6srm812dnYmXtUNhg/yo5ppaWlxOBwDA4MpU6ao/qmuri4nJydlk68RtUQ+Cs3/9NNPz549m5GRwefzZYVJSUk0Gs3f319TDxWXd/bs2ezs7MzMzHnz5tHpdGNj45ycHDs7O/llCgoKHjx4IF+ybdu2mTNnrly5UiqVjm684xPkx5GSnZ2t+sKpqal1dXXKJl8jaol8pJv/7NmzvXv37t+/n81my5c7OTkFBgb+9ttvO3fuHLm1q+jYsWOOjo4U72jt6uoKDg5OTExUKI+MjCwsLOxfDoYA8uOo+vnnn21tbYVCIZvNtre3/+677xBCgYGBQUFBZWVlGIZZWVkpTCKEent7IyIiRCIRh8OZMWMG8QLClJQUHo/H5XJzcnJWrFghEAhMTU3PnDmjrlBxHI+Pj582bRqLxdLV1XVzc3v8+DFCKCAggMlkyl4MsGXLFh6Ph2FYQ0ODQuRJSUlsNtvAwOCjjz4yNjZms9lOTk7Eu79VrwQhdPXqVfW+CzspKQnHcVdX1/6zoqOjp0yZcvLkyWvXrqneJ9TbgnTzUevp6bl165aDgwPFMuHh4Vu2bNHX11co19XVXbJkSWJi4nj9Cemo0tB7E18Dqr8HVf76I47j169fj4uLI/4uLS1FCB07doyYzMzMjIyMbGpqamxsnD9//oQJE4hyT09PS0tLWQ0Kkzt37mSxWFlZWc3NzWFhYTQa7c6dOziOh4eHI4SuX7/e2tpaV1e3ePFiHo/X09OjlnZFREQwmcxTp061tLQUFRU5OjpOnDixpqYGx/F169YZGhrKloyLi0MI1dfX94/c39+fx+M9fPiwu7u7pKRkzpw5fD6/qqpqUJVcunSJz+dHRUUNGDOu2vtdLSwsbG1tFQotLS3Ly8txHC8oKKDRaJMnT+7o6MBxPDc3V/b+a4o+odgWyjYfhfLycoSQg4PD0qVLjYyMWCyWjY3N0aNHZa+0zs/Pd3V1xZW8/zo0NBQhdP/+/QG7C97vSg2OH9WjtbVVdufa2dlZ2WJeXl779u3T1dXV09NzdXVtbGwk9m8K3d3dKSkp7u7unp6eOjo6e/bsYTAYaWlpsgWcnJwEAoG+vr6vr29nZ2dVVdXwm9PV1RUfH+/h4bF+/XqhUGhvb3/8+PGGhoYTJ04Mtio6nU4ccNna2qakpLS3t8sHrwoXF5e2tra9e/cOdtWkOjs7y8vLLS0tlS2wYMGC7du3V1RU7N69W75clT7pvy0G3HykiPsw+vr6MTExJSUltbW1bm5uW7du/eabb4hIAgMDU1JSlH3c2toaIVRcXKxalwClID+qh/zx448//qjKR4g3cA44GuPJkydisVh2YZ7D4RgZGRGndQqYTCZCSCKRDC50MiUlJR0dHbNnz5aVzJkzh8lkEmfHQzZ79mwul0sa/Kipq6vDcZz6rarR0dFTp05NTk7Oz8+XFQ6qT2TbQvXNJ4/FYiGEpk+f7uTkpKenJxQK9+/fLxQKiVwcFha2adMmExMTZR8nWldbW0u9FjAgyI/qt3TpUmUX+C9fvrx06VJ9fX0Wi7Vr1y5Vauvs7EQI7dmzR3Z8WllZKRaL1RlxP8QAEW1tbflCHR2d9vb2YdbMYrEGPGQeUd3d3eiPBKQMm81OS0vDMOyDDz7o6uoiCofWJ0PbfMbGxgihhoYGWQmTyTQzMysrK8vPzy8uLt64cSPFxzkcDvqjpWA4ID+OnqqqKnd3dyMjo9u3b7e2th46dEiVTxEX4BMSEuQvi4z0I7J1dHQQQgrf/JaWlmE+a1oikQy/kmEicseAh+0LFizYsWNHaWnpgQMHiJKh9cnQNp+2tra1tfXDhw/lC6VSqVAoTE1NvX79Oo1GI7ItUX9MTAyGYXfv3iWW7OnpkbUUDAfkx9FTXFwskUg+/vhjCwsLNpuNYZgqn5o0aRKbzS4sLBzp8OTZ2dlpa2vLvm8Iodu3b/f09MyaNQshRKfTh3YWn5eXh+P4/Pnzh1PJMBG/aFJlhOOBAwdsbGzu379PTFL3iTJD3nw+Pj73799//vw5MSkWiysrK+3t7dPS0uRTrfz9Gdm5P9E6Q0PDwa4UKID8OHpEIhFC6Nq1a93d3aWlpfLXrfT09F6+fFlRUdHe3i6RSOQntbS0NmzYcObMmZSUlLa2tt7e3urq6t9//31EQ2Wz2UFBQRcuXEhPT29raysuLt68ebOxsbG/vz9CyMrKqqmpKTs7WyKR1NfXV1ZWKmsIQqivr6+5uVkqlRYVFQUGBopEIj8/v0FVkpubq8bxPVwu18LCorq6WpVOSEtL09LSUqVPKCpRtvl8fX0NDQ2V/Wxxx44dZmZmfn5+VVVVjY2NISEhXV1dCreMlCFaRzF2EqhqxO6Mv/ZUGQfzyy+/yH4nY2Rk5OzsLD/3888/J/6H83g8Dw8PHMdDQkL09PR0dHS8vb2PHj2KELK0tKyqqrp3756ZmRmHw1m0aFFNTY3C5KtXr0JCQkQiEZ1O19fX9/T0LCkpSU5OJi7DW1tbl5WVnThxQiAQIITMzMyePn06zHbhON7X1xcXF2dtbc1gMHR1dd3d3Z88eULMamxsXLZsGZvNNjc3/+STT4KDgxFCVlZW/Rvi7+/PYDBMTEzodLpAIHBzcysrKxtsJVeuXOHz+dHR0QPGjKs2vicgIIDBYIjFYmLywoULxO3siRMnbt26VWHh4OBg2fgeZX1CvS1INx+O4+7u7gihiIgIZXG+ePFi7dq1urq6LBZr7ty5ubm5/ZchHd/j4uJiYmIiGwxEAcb3UIP8qJTq4x9fL6PZLn9/fz09vdFZF0GV/FhaWkqn00+dOjU6ISnT29u7ePHi1NRU9Vbb0NDAZrMPHz6sysKQH6nB+TUYWWPwcTJWVlZRUVFRUVH9H/cwanp7e7Ozs9vb2319fdVbc2RkpIODQ0BAgHqrfTNBfgRvotDQUG9vb19fX009iiIvL+/8+fO5ubnUIzEHKz4+vrCw8MqVK8ToWjBMkB/BSAkLC0tLS2ttbTU3N8/KytJ0OIpiYmICAgIOHjyokbU7OzufPn1a9gt0tcjJyXn16lVeXp6urq4aq32TwfuvwUiJjY2NjY3VdBRUli9fvnz5ck1HoTarV69evXq1pqMYV+D4EQAAyEF+BAAAcpAfAQCAHORHAAAgB/dnBuDt7a3pENSM+PHZ+GuXTEJCQmZmpqajeD3cunWL+Dk8IIXh8BB2JW7evBkfH6/pKN4s169ft7OzgwcrjCbiSUWajmKMgvwIxhAMw86dO7dmzRpNBwIAQnD9EQAAlIH8CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAADnIjwAAQA7yIwAAkIP8CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJCD/AgAAOQgPwIAADnIjwAAQA7yIwAAkIP8CAAA5CA/AgAAOciPAABADvIjAACQg/wIAADkID8CAAA5yI8AAEAO8iMAAJDDcBzXdAzgzfX+++/fv39fNvnixYsJEyZwuVxiksFgXLp06a233tJQdOBNR9d0AOCNNnXq1FOnTsmXtLa2yv62tbWF5Ag0CM6vgSatX78ewzDSWQwGw8/Pb3TDAeA/wPk10LDZs2ffu3ev/36IYdjz588nT56siaAAQAiOH4HGvf/++1paWgqFNBpt/vz5kByBZkF+BBrm6+vb19enUEij0d5//32NxAOADORHoGEGBgZLlixROITEcdzDw0NTIQFAgPwINO+9996Tv/6opaX1zjvvGBgYaDAkABDkRzAWeHp60un/N9QMx/H169drMB4ACJAfgeYJBIIVK1bIUiSdTnd1ddVsSAAgyI9gjFi/fn1vby9CiE6nr169WiAQaDoiACA/grHh3XffJX5W2Nvbu27dOk2HAwBCkB/BGMFmsz09PRFCPB7vr3/9q6bDAQAh+P21Km7evPnixQtNRzH+mZqaIoTmzJmTk5Oj6VjeCGvWrNF0CGMd/L5wYN7e3llZWZqOAgA1g+/+gOD8WiVeXl746w8hdO7cOU1HQSU6OloqlQ7hg15eXuNjG42Oc+fOafor9XqA/AjGkJCQkP6/xQZAUyA/gjFEfpQ4ABoH+REAAMhBfgT/X3t3HtVEmi4M/K2QpZKQQJBdBAnBDRAO7UbEUds59lHGBRna9EXnqD2349ZIgwwCyiCCysWrHGy43SrDPS6tqNjiAs4M9sUer7ajR2gFBkSUxUYEZElCgoRQ3x/1dZ1cSEKAQFCe31/mrcpTT9VLHmt5qwoAoBvURwAA0A3qIwAA6Ab1cRT98Y9/5PF4GIaVlpaaO5dhKigosLKyun79urkTMbGioqLY2Ni8vDyhUIhhGIZhGzdu1J5h+fLlPB7PwsLCy8vr8ePHY5yeWq0+ePCgSCRiMpnW1tbe3t61tbX95unu7p4xY8bevXsRQteuXUtNTSVvYAcmBPVxFJ06derkyZPmzmJEiA9xCPGf//znjIyMuLi4kJCQFy9eeHh4TJo06ezZszdv3qTm+dvf/nbp0qVVq1aVl5f7+/uPcYbr168/ffr0uXPnlErlv/71Lw8PD4VC0W+e+Pj4qqoq8t+rV6/GcXzZsmUdHR1jnOqHDeojMCQoKKizs3PVqlWjFF+lUonF4lEKrtPhw4cvXLhw8eJFHo9HNWZkZNBoNKlUqv12WXO5cOHC1atXL126NH/+fDqd7uTklJ+f7+3trT3PvXv3ysrKtFt27drl6+u7cuXK3t7esc33Qwb1cXTpe3kpIGVnZzc3N4/Z4p4/f75v3779+/fjOK7dLhaLIyIifvnll927d49ZMvr813/9l7+/v4+Pj74ZVCpVdHR0enp6v/bExMTS0tKB7WDYoD6aGEEQaWlp06dPZ7FYVlZW0dHR1CSNRpOQkODq6spms2fPnk3e45WVlcXlcjkcTn5+/ooVK/h8vouLy/nz58mv3LlzZ968eRwOh8/n+/j4yGQyfXFGw927d11dXTEM+/rrrw2nmpGRgeO4vb391q1bnZyccBwXi8UPHjxACIWHhzOZTEdHRzLmjh07uFwuhmGtra0RERFRUVE1NTUYholEIoTQrVu3+Hx+SkrKKK1RRkYGQRA6H76bnJw8bdq0U6dOFRUVDZxKEMTRo0dnzpzJYrEEAsHatWsrKysNbxM0rJ7q6en56aef/Pz8DMwTHx+/Y8cOOzu7fu0CgWDx4sXp6ekf5FkR8zDrbaDvhyHd2xsfH49h2H/+53+2t7crlcrMzEyEUElJCUEQu3fvZrFYly9fbm9vj4uLo9FoDx8+JL+CELp9+3ZnZ2dzc/OiRYu4XG5PT49CoeDz+ampqSqVqqmpad26dS0tLQbiDAoN/f5r8sFFx48fp9ZOZ6oEQUilUi6XW1FR0d3dXV5ePnfuXB6PV19fTxBEWFiYg4MDFTMtLQ0hRK5LSEiIh4cHNenGjRs8Hi8pKWlISRJG95FQKJw1a1a/Rg8Pj5cvXxIEce/ePRqNNnXqVIVCQRBEYWHhmjVryHkSEhKYTOaZM2c6OjqePHni7+9va2vb1NRkeJsMo6devnyJEPLz81uyZImjoyOLxZoxY8bXX3/d19dHznD37t3Vq1cTBNHS0oIQio+P1/56bGws9fdmAFmpB91cAPYfTUmlUh07duy3v/1tZGSktbU1m822sbEhJ3V3d2dlZQUHB4eEhFhbW+/du5fBYOTk5FDfFYvFfD7fzs5OIpF0dXXV19fX1tbKZDIvLy8cxx0cHPLy8mxtbQeNMwYGpkq20+l0cg9r1qxZWVlZcrl8qIkFBQXJZLJ9+/aNQtaoq6vr5cuXHh4e+mYICAj46quvamtr9+zZo92uUqmOHj26bt26DRs2WFlZ+fj4fPPNN62trSdOnKDmGbhNhtdT5HUYOzu7lJSU8vLyN2/erF27dufOnd999x2ZSURERFZWlr6ve3p6IoSePn1q3CYBu2EphgAAIABJREFUg4D6aErPnz9XKpXLli0bOKmqqkqpVFJn2dlstqOjI3mM1g+TyUQIqdVqoVBob2+/YcOGxMREaniH8XHGAJXqwElz5szhcDjmSkyn5uZmgiDIp5Trk5ycPH369MzMzLt371KN5eXlCoVizpw5VMvcuXOZTCZ5AqEfapsMr6dYLBZCyMvLSywW29jYWFlZ7d+/38rKiqzFcXFxX3zxxeTJk/V9nVy7N2/eGF4KMBLUR1N69eoVQmjgiSGEUFdXF0Jo79692K/q6uqUSqWBaGw2+4cffggMDExJSREKhRKJRKVSDSOOubBYLPIYcJzo7u5GvxYgfXAcz8nJwTBsy5YtKpWKbCQHzVhaWmrPaW1tLZfLDYQaXk85OTkhhFpbW6kWJpPp5uZWU1Nz9+7dp0+f/vGPfzTwdTabjX5dUzByUB9Nibwq+u7du4GTyKJ57Ngx7bMb9+/fNxzQy8vr+vXrjY2NMTExubm5R44cGV6csadWqzs6OshHgo8TZO0YdBB1QEBAZGRkdXX1gQMHyBZra2uEUL9qOOjaDa+nLC0tPT09KyoqtBt7e3utrKyys7Nv375No9HIakvGT0lJwTDs0aNH5Jw9PT3UmoKRg/poSt7e3jQa7c6dOwMnTZkyBcfxId1I09jYSP5O7OzsDh065O/vX1FRMYw4ZlFcXEwQxIIFCxBCdDpd5zH4GLO3t8cwzJgRjgcOHJgxY0ZJSQn50dvb29LSkqpBCKEHDx709PR89NFHBoIMu6fWr19fUlLy4sUL8qNSqayrq/Px8cnJydEutdrXZ6hjf3LtHBwchrpQoBPUR1Oys7P7/e9/f/ny5ezsbJlM9uTJE+oUPo7jmzdvPn/+fFZWlkwm02g0r169ev36tYFojY2NW7durays7OnpKSkpqaurW7BgwTDijJm+vr729vbe3t4nT55ERES4urpu2rQJISQSidra2q5evapWq1taWurq6qiv2NjYNDY21tbWyuVytVpdWFg4euN7OByOUCgkz4EYRh5lU0/qxXE8KirqypUrZ8+elclkT58+3bZtm5OTk1QqNRxEX09JJBIHBwd9ty1GRka6ublt2rSpvr7+7du3MTExKpWq3yUjfci1MzB2EgzN6FwW/6AMaXyPXC7/93//90mTJllaWgYGBiYkJCCEXFxcfv7553fv3sXExLi6utLpdDs7u5CQkPLy8szMTPKcuqenZ01NzYkTJ8hXP7u5uf39738Xi8UCgcDCwsLZ2Tk+Pp5894DOOMbkhoY4vuf48ePkuEUOh7N69WoDqT579kwqlTIYjMmTJ9PpdD6fv3bt2pqaGjLO27dvly5diuO4u7v7l19+SY4JFYlE9fX1jx8/dnNzY7PZgYGBTU1NBQUFPB4vOTnZ+CRJRvZReHg4g8FQKpXkxytXrpCXs21tbXfu3Nlv5ujoaGp8T19fX1pamqenJ4PBEAgEwcHBVVVVBEEY3ib6eio4OBghlJCQoC/PhoaGzz77TCAQsFisefPmFRYWDpxH5/ieoKCgyZMnU4OB9IHxPUaCbTS4D+bdJkOtj0MilUptbGxGKfigjOyj6upqOp1+5syZMUjJAI1Gs2jRouzsbNOGbW1txXH8yJEjg84J9dFIcHwNTGb8Pz9GJBIlJSUlJSUNfNzDmNFoNFevXpXL5RKJxLSRExMT/fz8wsPDTRt2IoP6CCaW2NjY0NBQiURirkdRFBcX5+XlFRYWGh6JOVRHjx4tLS0tKChgMBgmDDvBQX0EJhAXF5eTk9PZ2enu7j7+3xWekpISHh5+6NAhsyx92bJl586do25IN4n8/Px3794VFxcLBAIThgXwujhgAgcPHjx48KC5sxiC5cuXL1++3NxZmMyaNWvWrFlj7iw+QLD/CAAAukF9BAAA3aA+AgCAblAfAQBAN7g+Y5SffvopNDTU3FmYwLFjxy5dumTuLEzvp59+Qgh9GH00Boy5yRIg2H8EAAB9YP/RKAsWLPgAdrswDPvqq68+/fRTcydieuSe4wfQR2Pj4sWL69evN3cW7wHYfwQAAN2gPgIAgG5QHwEAQDeojwAAoBvURwAA0A3qo2nk5eUJhUJMC5PJtLe3X7JkSVpaWnt7u7kTBP9HUVFRbGysdq9t3LhRe4bly5fzeDwLCwsvLy99L0IYVX19fceOHROLxf3av/vuu7lz5/J4PDc3t82bNzc1NSGErl27lpqaOv6fv/n+MfcDet8Dxj8/3MPDw8rKiiAI8k0s//M//7Np0yYMw5ycnB4+fDjKaQ4Ojebzw81rSM94T0hIWLVqlUwmIz96eHhMmjQJIXTjxg3t2QoLC6n3K4yxZ8+eLVy4ECHk6+ur3X7hwgWEUGpqakdHR0lJiVAo9PPzU6vVBEGkp6cvXry4vb3dmPjw/HAjwf7jqMAwzNraesmSJTk5ORcvXnzz5k1QUJC5Hsg6BlQq1cA9HbMEGdThw4cvXLhw8eJFHo9HNWZkZNBoNKlUOh766Oeff96zZ8+2bdv8/Pz6Tfr222+dnZ2jo6OtrKz8/PwiIyNLS0sfPHiAENq1a5evr+/KlSt7e3vNkfWHCerjqPv973+/adOm5ubmb775xty5jJbs7Ozm5ubxEMSw58+f79u3b//+/eSbyilisTgiIuKXX37ZvXv3qCZgDF9f37y8vLCwMBaL1W9SQ0ODk5MThmHkxylTpiCEqPdBJiYmlpaWpqenj2W2Hzaoj2OBfM1pYWEhQkij0SQkJLi6urLZ7NmzZ5NHOllZWVwul8Ph5Ofnr1ixgs/nu7i4nD9/nvz6nTt35s2bx+Fw+Hy+j4+PTCbTF2fkCII4evTozJkzWSyWQCBYu3ZtZWUlQig8PJzJZFJPvd6xYweXy8UwrLW1NSIiIioqqqamBsMwkUiUkZGB47i9vf3WrVudnJxwHBeLxeQ+jvFBEEK3bt0y+bteMzIyCIJYvXr1wEnJycnTpk07depUUVGR8ZvFcMeZvI+EQqH2fyHkyUehUEh+FAgEixcvTk9PJwhihAsC/595D+/fC8M4/9gPWdGmTJlCEMTu3btZLNbly5fb29vj4uJoNBp5ajI+Ph4hdPv27c7Ozubm5kWLFnG53J6eHoVCwefzU1NTVSpVU1PTunXrWlpaDMQxABlx/jEhIYHJZJ45c6ajo+PJkyf+/v62trZNTU0EQYSFhTk4OFBzpqWlIYTIZEJCQjw8PKhJUqmUy+VWVFR0d3eXl5eT1xPq6+uHFOTGjRs8Hi8pKclwwiQj+0goFM6aNatfo4eHx8uXLwmCuHfvHo1Gmzp1qkKhIP7v+UcDm0VfxxHD6iNt8+fP73f+sbi4mMFgZGRkyGSysrKymTNnfvLJJ9ozxMbGIoRKSkoMR4bzj0aC/cexwOPxMAyTy+Xd3d1ZWVnBwcEhISHW1tZ79+5lMBg5OTnUnGKxmM/n29nZSSSSrq6u+vr62tpamUzm5eWF47iDg0NeXp6tre2gcYZHpVIdPXp03bp1GzZssLKy8vHx+eabb1pbW0+cODHUUHQ6ndzbmjVrVlZWllwuH2p6QUFBMpls3759Q120Pl1dXS9fviRfeK1TQEDAV199VVtbu2fPHu12YzbLwI4bjT5avHhxTExMeHg4n8/39vaWy+WnTp3SnsHT0xMh9PTp05EsBVCgPo6Frq4ugiD4fH5VVZVSqfT29ibb2Wy2o6MjeaTWD5PJRAip1WqhUGhvb79hw4bExMTa2lpyqvFxhqS8vFyhUMyZM4dqmTt3LpPJJI+Oh23OnDkcDmfk6Y1Qc3MzQRCG3xqYnJw8ffr0zMzMu3fvUo1D2ixUx41GH8XHx584ceL27dsKheLFixdisTggIKChoYGagVy7N2/ejGQpgAL1cSw8e/YMITRjxoyuri6E0N69e6lhknV1dUql0sB32Wz2Dz/8EBgYmJKSIhQKJRKJSqUaRhxjdHR0IIQsLS21G62treVy+Qgjs1islpaWEQYZoe7ubjITA/PgOJ6Tk4Nh2JYtW1QqFdk4vM1i8j56/fp1amrqF1988fHHH3O5XHd395MnTzY2NpLnKEhsNhv9uqZg5KA+joVbt24hhFasWGFnZ4cQOnbsmPY5jvv37xv+upeX1/Xr1xsbG2NiYnJzc48cOTK8OIOytrZGCPX72Xd0dLi4uIwkrFqtHnmQkSNrx6CDqAMCAiIjI6urqw8cOEC2DG+zmLyPqqurNRqNs7Mz1cLn821sbMrLy6mWnp4e9OuagpGD+jjqmpqajh075uLismXLlilTpuA4XlpaavzXGxsbKyoqEEJ2dnaHDh3y9/evqKgYRhxjeHt7W1paPnr0iGp58OBBT0/PRx99hBCi0+lqtXoYYYuLiwmCWLBgwUiCjJy9vT2GYcaMcDxw4MCMGTNKSkrIj4Y3iz4m7yOyHL9+/ZpqkcvlbW1t5CgfErl2Dg4OplroBAf10cQIglAoFH19fQRBtLS05ObmLly40MLC4urVq3w+H8fxzZs3nz9/PisrSyaTaTSaV69eaf/FD9TY2Lh169bKysqenp6SkpK6uroFCxYMI44xcByPioq6cuXK2bNnZTLZ06dPt23b5uTkJJVKEUIikaitre3q1atqtbqlpYUadocQsrGxaWxsrK2tlcvlZPkj7yDq7e198uRJRESEq6srOcjJ+CCFhYWmHd/D4XCEQqExrxYgj7ItLCyM2SwGgujrI4lE4uDgMNTbFt3d3ZcuXXry5Mkff/xRpVI1NDSQCXz++efUPOTa+fj4DCky0GuUr49/CIwZO3Lt2rXZs2dzOBwmk0mj0dCvt9DMmzcvKSnp7du31Jzv3r2LiYlxdXWl0+l2dnYhISHl5eWZmZnkmXVPT8+ampoTJ07w+XyEkJub29///nexWCwQCCwsLJydnePj43t7e/XFMZwkMmJ8T19fX1pamqenJ4PBEAgEwcHBVVVV5KS3b98uXboUx3F3d/cvv/wyOjoaISQSierr6x8/fuzm5sZmswMDA5uamqRSKYPBmDx5Mp1O5/P5a9eurampGWqQgoICHo+XnJxsOGGSkeN7wsPDGQyGUqkkP165coW8nG1ra7tz585+M0dHR1Pje/RtFgMd9+zZM319FBwcjBBKSEjQmeT9+/cXLlzo5ORE/kIdHR3FYvGdO3cIgiAHiopEIhaLZWlpuXDhwu+//177u0FBQZMnTyb/ezYAxvcYCbbR4IZ0b+94Zkx9NAmpVGpjYzMGC6IY2UfV1dV0Ov3MmTNjkJIBGo1m0aJF2dnZpg3b2tqK4/iRI0cGnRPqo5Hg+BqMivH5LBmRSJSUlJSUlKRQKMyVg0ajuXr1qlwul0gkpo2cmJjo5+cXHh5u2rATGdRHMLHExsaGhoZKJBJzPYqiuLg4Ly+vsLDQ8EjMoTp69GhpaWlBQQGDwTBh2AkO6iMwsbi4uJycnM7OTnd398uXL5s7HR1SUlLCw8MPHTpklqUvW7bs3Llz1E3oJpGfn//u3bvi4mKBQGDCsADe7wpM7ODBgwcPHjR3FoNYvnz58uXLzZ2FyaxZs2bNmjXmzuIDBPuPAACgG9RHAADQDeojAADoBvURAAB0g/oIAAC6YQQ8in0woaGh43OcCgAjAb/9QUF9HNz9+/e1H0EKRs/69esjIiICAgLMnciE8Omnn5o7hfEO6iMYRzAMy83Nhd8tGCfg/CMAAOgG9REAAHSD+ggAALpBfQQAAN2gPgIAgG5QHwEAQDeojwAAoBvURwAA0A3qIwAA6Ab1EQAAdIP6CAAAukF9BAAA3aA+AgCAblAfAQBAN6iPAACgG9RHAADQDeojAADoBvURAAB0g/oIAAC6QX0EAADdoD4CAIBuUB8BAEA3qI8AAKAb1EcAANAN6iMAAOgG9REAAHSD+ggAALpBfQQAAN2gPgIAgG5QHwEAQDeojwAAoBvURwAA0I1u7gTAhFZXV6fRaLRb3rx58+LFC+qjs7MzjuNjnhcACCGEEQRh7hzAxBUUFFRQUKBvKoPBePPmjUAgGMuUAKDA8TUwJ4lEom8SjUZbvnw5FEdgRlAfgTmtW7dO3+EzQRAbN24c43wA0Ab1EZgTl8v93e9+x2AwBk5isVi/+93vxj4lAChQH4GZhYWF9fb29mtkMBjr1q3jcrlmSQkAEtRHYGYrV660tLTs16hWq8PCwsySDwAUqI/AzJhMZmhoKJPJ1G7k8/m//e1vzZUSACSoj8D8/u3f/q2np4f6yGAwPvvss34VE4CxB+Mfgfn19fU5Ojq2tLRQLXfu3PnNb35jxpQAQLD/CMYDGo0WFhZGXcW2s7MLDAw0b0oAIKiPYJz47LPP1Go1QojJZG7atIlGg79MYH5wfA3GBYIgpk6dWl9fjxB69OjRRx99ZO6MAID9RzA+YBj2hz/8ASEkFAqhOIJxYsI9vyc0NNTcKQDdZDIZQgjHceijcSsyMjIgIMDcWYydCbf/ePny5VevXpk7i7H26tWry5cvmzuLQfD5fGtr6ylTpgz1ixOzT8fe5cuXGxoazJ3FmJpw+48Ioa+++urTTz81dxZj6uLFi+vXr7906ZK5ExlEUVHRMIaFYxg2Aft07GEYZu4UxtqE238E4xncMwPGFaiPAACgG9RHAADQDeojAADoBvURAAB0g/o4WjZv3ozjOIZh3d3d5s5lmAoKCqysrK5fv27uRMZOUVFRbGxsXl6eUCjEMAzDsH7veFi+fDmPx7OwsPDy8nr8+PHYZ9jX13fs2DGxWNyv/bvvvps7dy6Px3Nzc9u8eXNTUxNC6Nq1a6mpqf3eEAmMB/VxtOTk5OzevdvcWYzIRLv39M9//nNGRkZcXFxISMiLFy88PDwmTZp09uzZmzdvUvP87W9/u3Tp0qpVq8rLy/39/cc4w+rq6t/85jeRkZFKpVK7PTc3NywsLDQ09NWrV/n5+T/++OOKFSt6e3tXr16N4/iyZcs6OjrGONUPA9RHoFdQUFBnZ+eqVatGKb5KpRq4H2Quhw8fvnDhwsWLF3k8HtWYkZFBo9GkUmlnZ6cZcyP9/PPPe/bs2bZtm5+fX79J3377rbOzc3R0tJWVlZ+fX2RkZGlp6YMHDxBCu3bt8vX1Xbly5cCXWIBBQX0cdRNwVK2RsrOzm5ubzZ0FQgg9f/583759+/fv7/cyRbFYHBER8csvv4yHQwFfX9+8vLywsDAWi9VvUkNDg5OTE/WXRt6DVFdXR35MTEwsLS1NT08fy2w/DFAf9fqP//gPDofD4/Gam5ujoqImT55cVVWl0WgSEhJcXV3ZbPbs2bNzc3PJme/cuTNv3jwOh8Pn8318fMhbiRFCNBrt5s2bK1assLKycnJy+stf/kK2/+Mf/5g1a5aVlRWO4z4+Pn/9618RQhkZGTiO29vbb9261cnJCcdxsVhM7gUghPQtepTcvXvX1dUVw7Cvv/4aIZSVlcXlcjkcTn5+/ooVK/h8vouLy/nz5w2nHR4ezmQyHR0dyZg7duzgcrkYhrW2tkZERERFRdXU1GAYJhKJEEK3bt3i8/kpKSmjul46ZWRkEASxevXqgZOSk5OnTZt26tSpoqKigVMJgjh69OjMmTNZLJZAIFi7dm1lZSUyuLnQKHSlUCjU/p+GPPkoFArJjwKBYPHixenp6RPthIkJEBMMQig3N9fImePj4xFCu3btOn78+Lp16/71r3/t3r2bxWJdvny5vb09Li6ORqM9fPhQoVDw+fzU1FSVStXU1LRu3bqWlhbq67dv3+7o6Ghra1u5ciWLxerq6iII4tKlS4mJiW1tbW/fvl2wYMGkSZPIJUqlUi6XW1FR0d3dXV5eTp5xr6+vJwhC56KNXBHyFzjUbUXebHv8+HHtrXH79u3Ozs7m5uZFixZxudyenh7DaYeFhTk4OFAx09LSEELk9gkJCfHw8KAm3bhxg8fjJSUlDTXPIfWpTkKhcNasWf0aPTw8Xr58SRDEvXv3aDTa1KlTFQoFQRCFhYVr1qwh50lISGAymWfOnOno6Hjy5Im/v7+trW1TUxNhcHONpCsJgpg/f76vr692S3FxMYPByMjIkMlkZWVlM2fO/OSTT7RniI2NRQiVlJQMdctoG/l2fu9AfTSE/BNXqVTkR5VKxeFwJBIJ+VGpVLJYrO3bt5eVlSGEbty4Yfjrp0+fRgiVlZX1m+3gwYMIoebmZoIgpFKplZUVNenhw4cIof379+tbtJErYsL6SK1OZmYmQuj58+cG0iaGUh+HbYS/W4VCgWHYqlWr+rVT9ZEgiKioKITQzp07Ca36qFQqLS0tqU4hCOKf//wnQogs8fo21wi7ktBVHwmC2Lt3L7XT4+Li0tDQoD2VPHA5ffq08UsZaALWRzi+HoKqqiqlUunt7U1+ZLPZjo6OlZWVQqHQ3t5+w4YNiYmJtbW1+r5Ovj+AfEr2wHadgzDmzJnD4XAqKyv1LdoUqzVM5PuzBq4O0kp7zJMaDvJ/Jg6HY2Ce5OTk6dOnZ2Zm3r17l2osLy9XKBRz5syhWubOnctkMqlTItqozTUaXRkfH3/ixInbt28rFIoXL16IxeKAgADtZ+2Qa/fmzZuRLGUCgvo4BF1dXQihvXv3Yr+qq6tTKpVsNvuHH34IDAxMSUkRCoUSiUSlUhkOdfPmzSVLltjZ2bFYrD/96U8G5mSxWC0tLfoWbcK1My0ybXNnYRRygOrAix7acBzPycnBMGzLli1U55KDZvq9vNva2loulxsIZfKufP36dWpq6hdffPHxxx9zuVx3d/eTJ082NjaSu+okNpuNfl1TYDyoj0NgZ2eHEDp27Jj2Hvj9+/cRQl5eXtevX29sbIyJicnNzT1y5IiBOPX19cHBwY6Ojg8ePOjs7ExNTdU3p1qt7ujocHFxMbDocYhK29yJGIWsHYMOog4ICIiMjKyurj5w4ADZYm1tjRDqVw0HXXGTd2V1dbVGo3F2dqZa+Hy+jY1NeXk51UK+PpdcU2A8qI9DMGXKFBzHS0tL+7U3NjZWVFQghOzs7A4dOuTv709+1Ofp06dqtXr79u1CoZC8x0bfnMXFxQRBLFiwQN+ixycqbYQQnU7XeQw+ftjb22MYZswIxwMHDsyYMaOkpIT86O3tbWlp+ejRI2qGBw8e9PT0GH4/hMm7kizHr1+/plrkcnlbW5v2k4bJtXNwcDDVQicIqI9DgOP45s2bz58/n5WVJZPJNBrNq1evXr9+3djYuHXr1srKyp6enpKSkrq6OrI06OPq6ooQKioq6u7urq6u7ne6qq+vr729vbe398mTJxEREa6urps2bdK36NFd4aHQmTZCSCQStbW1Xb16Va1Wt7S0UIPyEEI2NjaNjY21tbVyuVytVhcWFpplfA+HwxEKhcY8gZw8yrawsKA+RkVFXbly5ezZszKZ7OnTp9u2bXNycpJKpYaD6OtKiUTi4OAw1NsW3d3dly5devLkyR9//FGlUjU0NJAJfP7559Q85Nr5+PgMKTKA69d6paamkscjU6ZMOXPmDNn47t27mJgYV1dXOp1uZ2cXEhJSXl5eW1srFosFAoGFhYWzs3N8fHxvby/1dU9Pz5qamrNnzwoEAoSQi4tLWVlZTEyMjY2NtbV1aGgoOcDQw8Ojvr5eKpUyGIzJkyfT6XQ+n7927dqamhoDizZyrYdx/fr48ePkuEUOh7N69erMzEzyHD+5OidOnODz+QghNze3Z8+eGUj77du3S5cuxXHc3d39yy+/jI6ORgiJRKL6+vrHjx+7ubmx2ezAwMCmpqaCggIej5ecnDykPAlTXFcNDw9nMBhKpZL8eOXKFQ8PD4SQra0tec1aW3R0NDW+p6+vLy0tzdPTk8FgCASC4ODgqqoqgiAMby59XRkcHIwQSkhI0Jnk/fv3Fy5c6OTkRP5yHR0dxWLxnTt3CIIgx5OKRCIWi2Vpablw4cLvv/9e+7tBQUGTJ0/u6+sbyVYa+XZ+70B9HF+kUqmNjY3Jww5vfI/xRiltI428T6urq+l0OvW/oLloNJpFixZlZ2ebNmxrayuO40eOHBlhnHH+2xkNcHw97rynT1t5T9MmiUSipKSkpKQkhUJhrhw0Gs3Vq1flcrlEIjFt5MTERD8/v/DwcNOGnQigPgKAEEKxsbGhoaESicRcj6IoLi7Oy8srLCw0PBJzqI4ePVpaWlpQUEAOswVDAvVxHImLi8vJyens7HR3dx//r2OlvKdpD5SSkhIeHn7o0CGzLH3ZsmXnzp2j7lU3ifz8/Hfv3hUXF5PnvsFQYcQEu2Udw7Dc3NyJ9i5Q8v2uH2pfT8w+HXsTcDvD/iMAAOgG9REAAHSD+ggAALpBfQQAAN2gPgIAgG4T8fq1uVMA4H010a5f082dgBlEREQEBASYO4sxdf/+/fT09NF+ZY25rF+/fgL26dhbv369uVMYaxOxPgYEBEyo/wNJ6enpH+par1+/fmL26RibgPURzj8CAIBuUB8BAEA3qI8AAKAb1EcAANAN6iMAAOgG9bG/vLw8oVCIaSHfDbBly5aXL18OI+DmzZvJl3DB2zXHg6KiotjYWO1e3rhxo/YMy5cv5/F4FhYWXl5eQ30VjEn09fUdO3ZMLBb3a//uu+/mzp3L4/Hc3Nw2b97c1NQ0kpjXrl1LTU19r59qPBbM/PzyMYeMe0a8h4eHlZUVQRAajebNmzenT5/mcDj29vatra3DWGh8fDxCSKVSDeO7JjHa71cwLyP7lCCIhISEVatWyWQy8qOHh8ekSZMQQjdu3NCerbCwkHrDzBh79uzZwoULEUK+vr7a7RcuXEAIpaamdnR0lJSUCIVCPz8/tVo9kpjp6emLFy9ub283Mjfjt/MHA/YfB0Gj0ezt7Tdu3Lhz587m5uaioiJzZzTuqFSqgTs7Zgli2OHDhy9cuHDx4kUej0c1ZmRk0Gg0qVRqrseGa/v555/37Nmzbds2Pz+/fpO+/fZbZ2fn6OhoKysrPz+/yMhB1desAAAKHElEQVTI0tLSfm++HGrMXbt2+fr6rly5sre312Tr8GGB+mgskUiEEBrSQU0/H+qtjdnZ2c3NzeMhiAHPnz/ft2/f/v37cRzXbheLxREREb/88svu3btHb+lG8vX1zcvLCwsLY7FY/SY1NDQ4OTlRf0Lku621X5Y7jJgIocTExNLS0vT09BHn/mGC+mis6upqhJCvry/5UaPRJCQkuLq6stns2bNnU7fu3blzZ968eRwOh8/n+/j4yGQysp1Go928eXPFihVWVlZOTk5/+ctfyPZ//OMfs2bNsrKywnHcx8fnr3/9K0IoIyMDx3F7e/utW7c6OTnhOC4Wi6mdBX2LHjmCII4ePTpz5kwWiyUQCNauXVtZWYkQCg8PZzKZ1KP/d+zYweVyMQwjXysaFRVVU1ODYZhIJDKQufFBEEK3bt0y7buwMzIyCIJYvXr1wEnJycnTpk07deqUzoMDfdskKyuLy+VyOJz8/PwVK1bw+XwXF5fz58+T3zJ5HwmFQu3/P8j/p4VC4QjDCgSCxYsXp6enExPsOQzGMu/h/dhDQzz/SBBEe3v7f//3f3M4nKCgIGqG3bt3s1isy5cvt7e3x8XF0Wi0hw8fKhQKPp+fmpqqUqmamprWrVvX0tJC/Hr+8fbt2x0dHW1tbStXrmSxWF1dXQRBXLp0KTExsa2t7e3btwsWLJg0aRIZXyqVcrncioqK7u7u8vJy8sR8fX29vkUbXh0jzz8mJCQwmcwzZ850dHQ8efLE39/f1ta2qamJIIiwsDAHBwdqzrS0NIQQuXYhISEeHh7UJAOZGx/kxo0bPB4vKSlp0JwJ4/pUKBTOmjWrX6OHh8fLly8Jgrh37x6NRps6dapCoSD+7/lHA9uE6tbOzs7m5uZFixZxudyenh5iWH2kbf78+f3OFRYXFzMYjIyMDJlMVlZWNnPmzE8++cT4gDpjkmJjYxFCJSUlg0Yw8rfzIYH6qBv5engKhmHJycnknz5BECqVisPhSCQS8qNSqWSxWNu3by8rK0MDTvYTA67PnD59GiFUVlbWb7aDBw8ihJqbmwmCkEqlVIEmCOLhw4cIof379+tbtOHVMaY+KpVKS0tLKjJBEP/85z8RQmSRGlJ91Jn5kIIMyaB9qlAoMAxbtWpVv3aqPhIEERUVhRDauXMnoVUfDW+Tft2amZmJEHr+/Pnw+kibzlq2d+9e6g/SxcWloaHB+ID6YhIEQR7KnD59etAIE7A+wvG1XtSPPDo6miAIKysr6g2ZVVVVSqXS29ub/Mhmsx0dHSsrK4VCob29/YYNGxITE2tra/VFJuOo1Wqd7TqHXMyZM4fD4VRWVupb9EjXFqHy8nKFQjFnzhyqZe7cuUwm05iLAAZQmY84weEj/8sx/N7U5OTk6dOnZ2Zm3r17l2oc0jZhMpkIIbVaPRp9FB8ff+LEidu3bysUihcvXojF4oCAgIaGhpHEJJGb5c2bNyMP9eGB+ji4ffv2OTo6xsXFUX+OXV1dCKG9e/dSYyTr6uqUSiWbzf7hhx8CAwNTUlKEQqFEIlGpVIaD37x5c8mSJXZ2diwW609/+pOBOVksVktLi75Fj3w1Ozo6EEKWlpbajdbW1nK5fISRycxHGGQkyJGnOi9QUHAcz8nJwTBsy5YtVK8Nb5uYvI9ev36dmpr6xRdffPzxx1wu193d/eTJk42NjeQO+Aix2Wz06yYC/UB9HByPxzt8+LBcLt++fTvZYmdnhxA6duyY9q74/fv3EUJeXl7Xr19vbGyMiYnJzc09cuSIgcj19fXBwcGOjo4PHjzo7OxMTU3VN6dare7o6HBxcTGw6BGytrZGCPX75ZMLHUlYKvMRJTcyZAkYdCx0QEBAZGRkdXX1gQMHyJbhbROT91F1dbVGo3F2dqZa+Hy+jY1NeXn5sGNSenp60K+bCPQD9dEof/jDH+bPn3/jxo2LFy8ihKZMmYLjeGlpab/ZGhsbKyoqEEJ2dnaHDh3y9/cnP+rz9OlTtVq9fft2oVBI3mOjb87i4mKCIBYsWKBv0SPn7e1taWn56NEjquXBgwc9PT0fffQRQohOpw88IWAMKvORBBkhe3t7DMOMGeF44MCBGTNmlJSUkB8NbxN9TN5HZDl+/fo11SKXy9va2shRPiNEbhYHB4eRh/rwQH00CoZhGRkZGIaFh4e3t7fjOL558+bz589nZWXJZDKNRvPq1avXr183NjZu3bq1srKyp6enpKSkrq6OrAv6uLq6IoSKioq6u7urq6v7ndXq6+trb2/v7e198uRJRESEq6vrpk2b9C165OuI43hUVNSVK1fOnj0rk8mePn26bds2JycnqVSKEBKJRG1tbVevXlWr1S0tLdoj72xsbBobG2tra+VyOVn+dGY+pCCFhYUmHN/D4XCEQuGrV6+M2Qg5OTkWFhbGbBMDQfT1kUQicXBwGOpti+7u7kuXLj158uSPP/6oUqkaGhrIBD7//PNhx6SQm8XHx2d4X//AjebFn/EIDXYN7n//93+nTZtGbhxnZ+etW7dSk8gfubW19aFDh969excTE+Pq6kqn0+3s7EJCQsrLy2tra8VisUAgsLCwcHZ2jo+P7+3tTU1NJQ9ePD09a2pqzp49KxAIEEIuLi5lZWUxMTE2NjbW1tahoaFff/01QsjDw6O+vl4qlTIYjMmTJ9PpdD6fv3bt2pqaGjINnYs2vNZGju/p6+tLS0vz9PRkMBgCgSA4OLiqqoqc9Pbt26VLl5K3on/55ZfR0dEIIZFIVF9f//jxYzc3NzabHRgY2NTUZCBz44MUFBTweLzk5ORBcyaMu64aHh7OYDCUSiX58cqVK+QQBVtbW/Katbbo6GhqfI++bZKZmUle2SC79cSJE3w+HyHk5ub27NkzfX0UHByMEEpISNCZ5P379xcuXOjk5ET++Tk6OorF4jt37hAEQY4SFYlELBbL0tJy4cKF33//PfmtYcckBQUFTZ48ua+vz/AGJCbk9Wuoj+OUVCq1sbExVbSxvP/atJkbw5g+ra6uptPpZ86cGZuU9NFoNIsWLcrOzh4nMVtbW3EcP3LkiDEzvy+/HROC4+vx6/19tso4zFwkEiUlJSUlJSkUCnPloNForl69KpfLJRLJOImZmJjo5+cXHh5uqnw+MFAfwUQRGxsbGhoqkUjM9SiK4uLivLy8wsJCwyMxxyzm0aNHS0tLCwoKqIG9oB+oj+NRXFxcTk5OZ2enu7v75cuXzZ3OEIzzzFNSUsLDww8dOmSWpS9btuzcuXPUHejmjZmfn//u3bvi4mLybDjQCSMm2H3pGIZNtHecI4QuXry4fv36D7WvJ2afjr0JuJ1h/xEAAHSD+ggAALpBfQQAAN2gPgIAgG50cydgBiZ5msP7hVxl8ubxD9IE7FMwBibi9WtzpwDA+2qiXb+ecPURAACMBOcfAQBAN6iPAACgG9RHAADQDeojAADo9v8AQooHip7vCfsAAAAASUVORK5CYII=",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = build_CONV_GRU_DENSE_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6wvJE3LubmM"
      },
      "source": [
        "### 5.2 Training loop and callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7G8QMjKsgk_",
        "outputId": "c402890d-0634-4051-e48b-00d9c920a056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0712\n",
            "Epoch 1: val_loss improved from inf to 0.01302, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch01_Loss0.0130\n",
            "891/891 [==============================] - 35s 30ms/step - loss: 0.0712 - val_loss: 0.0130 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0128\n",
            "Epoch 2: val_loss improved from 0.01302 to 0.01278, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch02_Loss0.0128\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0128 - val_loss: 0.0128 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0127\n",
            "Epoch 3: val_loss improved from 0.01278 to 0.01242, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch03_Loss0.0124\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0127 - val_loss: 0.0124 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0126\n",
            "Epoch 4: val_loss did not improve from 0.01242\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0126 - val_loss: 0.0124 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0125\n",
            "Epoch 5: val_loss improved from 0.01242 to 0.01211, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch05_Loss0.0121\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0125 - val_loss: 0.0121 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0122\n",
            "Epoch 6: val_loss improved from 0.01211 to 0.01172, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch06_Loss0.0117\n",
            "891/891 [==============================] - 28s 32ms/step - loss: 0.0122 - val_loss: 0.0117 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0119\n",
            "Epoch 7: val_loss improved from 0.01172 to 0.01168, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch07_Loss0.0117\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0119 - val_loss: 0.0117 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0117\n",
            "Epoch 8: val_loss improved from 0.01168 to 0.01153, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch08_Loss0.0115\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0117 - val_loss: 0.0115 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0115\n",
            "Epoch 9: val_loss did not improve from 0.01153\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0115 - val_loss: 0.0118 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0112\n",
            "Epoch 10: val_loss improved from 0.01153 to 0.01088, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch10_Loss0.0109\n",
            "891/891 [==============================] - 28s 31ms/step - loss: 0.0112 - val_loss: 0.0109 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0109\n",
            "Epoch 11: val_loss improved from 0.01088 to 0.01064, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch11_Loss0.0106\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0109 - val_loss: 0.0106 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0106\n",
            "Epoch 12: val_loss improved from 0.01064 to 0.01035, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch12_Loss0.0103\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0106 - val_loss: 0.0103 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0104\n",
            "Epoch 13: val_loss improved from 0.01035 to 0.01030, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch13_Loss0.0103\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0104 - val_loss: 0.0103 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0102\n",
            "Epoch 14: val_loss improved from 0.01030 to 0.00981, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch14_Loss0.0098\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0102 - val_loss: 0.0098 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0100\n",
            "Epoch 15: val_loss improved from 0.00981 to 0.00967, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch15_Loss0.0097\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0100 - val_loss: 0.0097 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0098\n",
            "Epoch 16: val_loss improved from 0.00967 to 0.00962, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch16_Loss0.0096\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0098 - val_loss: 0.0096 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 17: val_loss improved from 0.00962 to 0.00943, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch17_Loss0.0094\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0097 - val_loss: 0.0094 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0096\n",
            "Epoch 18: val_loss did not improve from 0.00943\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0096 - val_loss: 0.0095 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0095\n",
            "Epoch 19: val_loss improved from 0.00943 to 0.00924, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch19_Loss0.0092\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0095 - val_loss: 0.0092 - lr: 0.0010\n",
            "Epoch 20/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0094\n",
            "Epoch 20: val_loss improved from 0.00924 to 0.00917, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch20_Loss0.0092\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0094 - val_loss: 0.0092 - lr: 0.0010\n",
            "Epoch 21/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0093\n",
            "Epoch 21: val_loss did not improve from 0.00917\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0093 - val_loss: 0.0093 - lr: 0.0010\n",
            "Epoch 22/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0093\n",
            "Epoch 22: val_loss improved from 0.00917 to 0.00911, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch22_Loss0.0091\n",
            "891/891 [==============================] - 25s 29ms/step - loss: 0.0093 - val_loss: 0.0091 - lr: 0.0010\n",
            "Epoch 23/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0092\n",
            "Epoch 23: val_loss improved from 0.00911 to 0.00907, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch23_Loss0.0091\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0092 - val_loss: 0.0091 - lr: 0.0010\n",
            "Epoch 24/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 24: val_loss improved from 0.00907 to 0.00896, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch24_Loss0.0090\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0092 - val_loss: 0.0090 - lr: 0.0010\n",
            "Epoch 25/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0091\n",
            "Epoch 25: val_loss did not improve from 0.00896\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0091 - val_loss: 0.0092 - lr: 0.0010\n",
            "Epoch 26/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0091\n",
            "Epoch 26: val_loss improved from 0.00896 to 0.00888, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch26_Loss0.0089\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0091 - val_loss: 0.0089 - lr: 0.0010\n",
            "Epoch 27/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0090\n",
            "Epoch 27: val_loss improved from 0.00888 to 0.00881, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch27_Loss0.0088\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0090 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 28/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0090\n",
            "Epoch 28: val_loss improved from 0.00881 to 0.00878, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch28_Loss0.0088\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0090 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 29/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0089\n",
            "Epoch 29: val_loss improved from 0.00878 to 0.00876, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch29_Loss0.0088\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0089 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 30/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0089\n",
            "Epoch 30: val_loss improved from 0.00876 to 0.00875, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch30_Loss0.0088\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0089 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 31/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0089\n",
            "Epoch 31: val_loss did not improve from 0.00875\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0088 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 32/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0088\n",
            "Epoch 32: val_loss improved from 0.00875 to 0.00862, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch32_Loss0.0086\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0088 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 33/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0088\n",
            "Epoch 33: val_loss improved from 0.00862 to 0.00853, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch33_Loss0.0085\n",
            "891/891 [==============================] - 28s 31ms/step - loss: 0.0088 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 34/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 34: val_loss did not improve from 0.00853\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0087 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 35/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0087\n",
            "Epoch 35: val_loss did not improve from 0.00853\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0087 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 36/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0087\n",
            "Epoch 36: val_loss improved from 0.00853 to 0.00850, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch36_Loss0.0085\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0087 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 37/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0086\n",
            "Epoch 37: val_loss did not improve from 0.00850\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0086 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 38/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0086\n",
            "Epoch 38: val_loss improved from 0.00850 to 0.00837, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch38_Loss0.0084\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0086 - val_loss: 0.0084 - lr: 0.0010\n",
            "Epoch 39/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 39: val_loss did not improve from 0.00837\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0086 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 40/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 40: val_loss did not improve from 0.00837\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0086 - val_loss: 0.0084 - lr: 0.0010\n",
            "Epoch 41/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0085\n",
            "Epoch 41: val_loss improved from 0.00837 to 0.00834, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch41_Loss0.0083\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0085 - val_loss: 0.0083 - lr: 0.0010\n",
            "Epoch 42/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0085\n",
            "Epoch 42: val_loss improved from 0.00834 to 0.00827, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch42_Loss0.0083\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0085 - val_loss: 0.0083 - lr: 0.0010\n",
            "Epoch 43/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0085\n",
            "Epoch 43: val_loss did not improve from 0.00827\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0085 - val_loss: 0.0084 - lr: 0.0010\n",
            "Epoch 44/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0085\n",
            "Epoch 44: val_loss did not improve from 0.00827\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0085 - val_loss: 0.0083 - lr: 0.0010\n",
            "Epoch 45/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0084\n",
            "Epoch 45: val_loss improved from 0.00827 to 0.00823, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch45_Loss0.0082\n",
            "891/891 [==============================] - 25s 29ms/step - loss: 0.0084 - val_loss: 0.0082 - lr: 0.0010\n",
            "Epoch 46/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 46: val_loss improved from 0.00823 to 0.00812, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch46_Loss0.0081\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0084 - val_loss: 0.0081 - lr: 0.0010\n",
            "Epoch 47/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0084\n",
            "Epoch 47: val_loss improved from 0.00812 to 0.00810, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch47_Loss0.0081\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0084 - val_loss: 0.0081 - lr: 0.0010\n",
            "Epoch 48/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 48: val_loss did not improve from 0.00810\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0083 - val_loss: 0.0082 - lr: 0.0010\n",
            "Epoch 49/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 49: val_loss did not improve from 0.00810\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0083 - val_loss: 0.0082 - lr: 0.0010\n",
            "Epoch 50/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 50: val_loss improved from 0.00810 to 0.00809, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch50_Loss0.0081\n",
            "891/891 [==============================] - 25s 29ms/step - loss: 0.0083 - val_loss: 0.0081 - lr: 0.0010\n",
            "Epoch 51/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 51: val_loss improved from 0.00809 to 0.00803, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch51_Loss0.0080\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0083 - val_loss: 0.0080 - lr: 0.0010\n",
            "Epoch 52/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0082\n",
            "Epoch 52: val_loss did not improve from 0.00803\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0082 - val_loss: 0.0081 - lr: 0.0010\n",
            "Epoch 53/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0082\n",
            "Epoch 53: val_loss improved from 0.00803 to 0.00794, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch53_Loss0.0079\n",
            "891/891 [==============================] - 24s 26ms/step - loss: 0.0082 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 54/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 54: val_loss did not improve from 0.00794\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0082 - val_loss: 0.0080 - lr: 0.0010\n",
            "Epoch 55/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 55: val_loss did not improve from 0.00794\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0082 - val_loss: 0.0080 - lr: 0.0010\n",
            "Epoch 56/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 56: val_loss did not improve from 0.00794\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0082 - val_loss: 0.0081 - lr: 0.0010\n",
            "Epoch 57/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 57: val_loss did not improve from 0.00794\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0081 - val_loss: 0.0080 - lr: 0.0010\n",
            "Epoch 58/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0081\n",
            "Epoch 58: val_loss improved from 0.00794 to 0.00787, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch58_Loss0.0079\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0081 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 59/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 59: val_loss did not improve from 0.00787\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0081 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 60/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0081\n",
            "Epoch 60: val_loss improved from 0.00787 to 0.00783, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch60_Loss0.0078\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0081 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 61/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 61: val_loss improved from 0.00783 to 0.00779, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch61_Loss0.0078\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0081 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 62/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0081\n",
            "Epoch 62: val_loss did not improve from 0.00779\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0081 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 63/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 63: val_loss did not improve from 0.00779\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0080 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 64/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 64: val_loss improved from 0.00779 to 0.00779, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch64_Loss0.0078\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0080 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 65/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 65: val_loss improved from 0.00779 to 0.00777, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch65_Loss0.0078\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0080 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 66/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 66: val_loss did not improve from 0.00777\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0080 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 67/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 67: val_loss improved from 0.00777 to 0.00773, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch67_Loss0.0077\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 68/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 68: val_loss did not improve from 0.00773\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0080 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 69/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 69: val_loss improved from 0.00773 to 0.00765, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch69_Loss0.0076\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0080 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 70/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 70: val_loss did not improve from 0.00765\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 71/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 71: val_loss did not improve from 0.00765\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0079 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 72/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 72: val_loss improved from 0.00765 to 0.00763, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch72_Loss0.0076\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 73/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 73: val_loss did not improve from 0.00763\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 74/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 74: val_loss improved from 0.00763 to 0.00762, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch74_Loss0.0076\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 75/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 75: val_loss did not improve from 0.00762\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0079 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 76/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 76: val_loss improved from 0.00762 to 0.00761, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch76_Loss0.0076\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 77/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 77: val_loss improved from 0.00761 to 0.00755, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch77_Loss0.0075\n",
            "891/891 [==============================] - 24s 26ms/step - loss: 0.0079 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 78/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 78: val_loss did not improve from 0.00755\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0079 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 79/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 79: val_loss did not improve from 0.00755\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 80/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 80: val_loss did not improve from 0.00755\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 81/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 81: val_loss improved from 0.00755 to 0.00751, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch81_Loss0.0075\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 82/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 82: val_loss did not improve from 0.00751\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0078 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 83/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 83: val_loss did not improve from 0.00751\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0078 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 84/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 84: val_loss did not improve from 0.00751\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0078 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 85/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 85: val_loss improved from 0.00751 to 0.00750, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch85_Loss0.0075\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 86/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 86: val_loss did not improve from 0.00750\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0078 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 87/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 87: val_loss did not improve from 0.00750\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0078 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 88/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 88: val_loss improved from 0.00750 to 0.00746, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch88_Loss0.0075\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 89/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 89: val_loss did not improve from 0.00746\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 90/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 90: val_loss did not improve from 0.00746\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0078 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 91/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 91: val_loss did not improve from 0.00746\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 92/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 92: val_loss improved from 0.00746 to 0.00739, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch92_Loss0.0074\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 93/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 93: val_loss did not improve from 0.00739\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 94/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 94: val_loss did not improve from 0.00739\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 95/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 95: val_loss improved from 0.00739 to 0.00735, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch95_Loss0.0074\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 96/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 96: val_loss did not improve from 0.00735\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 97/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 97: val_loss did not improve from 0.00735\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 98/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 98: val_loss did not improve from 0.00735\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 99/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 99: val_loss improved from 0.00735 to 0.00733, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch99_Loss0.0073\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0077 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 100/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 100: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 101/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 101: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0077 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 102/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 102: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0077 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 103/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 103: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 104/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 104: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 105/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 105: val_loss did not improve from 0.00733\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 106/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0076\n",
            "Epoch 106: val_loss improved from 0.00733 to 0.00733, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch106_Loss0.0073\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 107/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 107: val_loss improved from 0.00733 to 0.00732, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch107_Loss0.0073\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 108/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 108: val_loss did not improve from 0.00732\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 109/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 109: val_loss did not improve from 0.00732\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 110/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 110: val_loss did not improve from 0.00732\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 111/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0076\n",
            "Epoch 111: val_loss did not improve from 0.00732\n",
            "891/891 [==============================] - 15s 17ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 112/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 112: val_loss did not improve from 0.00732\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
            "Epoch 113/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 113: val_loss improved from 0.00732 to 0.00730, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch113_Loss0.0073\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 114/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 114: val_loss improved from 0.00730 to 0.00729, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch114_Loss0.0073\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 115/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 115: val_loss did not improve from 0.00729\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 116/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 116: val_loss did not improve from 0.00729\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 117/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 117: val_loss improved from 0.00729 to 0.00724, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch117_Loss0.0072\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0076 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 118/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0076\n",
            "Epoch 118: val_loss did not improve from 0.00724\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 119/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 119: val_loss did not improve from 0.00724\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0075 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 120/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0076\n",
            "Epoch 120: val_loss did not improve from 0.00724\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0076 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 121/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 121: val_loss did not improve from 0.00724\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 122/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 122: val_loss improved from 0.00724 to 0.00722, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch122_Loss0.0072\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 123/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 123: val_loss did not improve from 0.00722\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 124/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 124: val_loss did not improve from 0.00722\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0075 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 125/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 125: val_loss did not improve from 0.00722\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 126/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 126: val_loss improved from 0.00722 to 0.00718, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch126_Loss0.0072\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 127/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 127: val_loss improved from 0.00718 to 0.00717, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch127_Loss0.0072\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 128/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 128: val_loss did not improve from 0.00717\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 129/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 129: val_loss did not improve from 0.00717\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 130/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 130: val_loss did not improve from 0.00717\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 131/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 131: val_loss did not improve from 0.00717\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 132/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 132: val_loss did not improve from 0.00717\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 133/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 133: val_loss improved from 0.00717 to 0.00716, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch133_Loss0.0072\n",
            "891/891 [==============================] - 23s 26ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 134/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 134: val_loss did not improve from 0.00716\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 135/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 135: val_loss did not improve from 0.00716\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0075 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 136/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 136: val_loss did not improve from 0.00716\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 137/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 137: val_loss did not improve from 0.00716\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 138/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 138: val_loss improved from 0.00716 to 0.00715, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch138_Loss0.0072\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 139/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 139: val_loss did not improve from 0.00715\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 140/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 140: val_loss did not improve from 0.00715\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 141/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 141: val_loss did not improve from 0.00715\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 142/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 142: val_loss improved from 0.00715 to 0.00712, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch142_Loss0.0071\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 143/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 143: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 144/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 144: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 145/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 145: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 146/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 146: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 147/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 147: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 148/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 148: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 149/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 149: val_loss did not improve from 0.00712\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 150/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 150: val_loss improved from 0.00712 to 0.00710, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch150_Loss0.0071\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 151/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 151: val_loss did not improve from 0.00710\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 152/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 152: val_loss did not improve from 0.00710\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 153/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 153: val_loss improved from 0.00710 to 0.00708, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch153_Loss0.0071\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 154/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 154: val_loss did not improve from 0.00708\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 155/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 155: val_loss did not improve from 0.00708\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 156/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 156: val_loss did not improve from 0.00708\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 157/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 157: val_loss improved from 0.00708 to 0.00705, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch157_Loss0.0071\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 158/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 158: val_loss did not improve from 0.00705\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 159/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 159: val_loss did not improve from 0.00705\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 160/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 160: val_loss did not improve from 0.00705\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 161/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 161: val_loss improved from 0.00705 to 0.00703, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch161_Loss0.0070\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 162/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 162: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 163/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 163: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 164/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 164: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 17ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 165/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 165: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 166/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 166: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 167/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 167: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 168/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 168: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 169/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 169: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 170/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 170: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 171/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 171: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 172/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 172: val_loss did not improve from 0.00703\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 173/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 173: val_loss improved from 0.00703 to 0.00701, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch173_Loss0.0070\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 174/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 174: val_loss improved from 0.00701 to 0.00699, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch174_Loss0.0070\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 175/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 175: val_loss did not improve from 0.00699\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 176/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 176: val_loss did not improve from 0.00699\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 177/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 177: val_loss did not improve from 0.00699\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 178/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 178: val_loss improved from 0.00699 to 0.00697, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch178_Loss0.0070\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0073 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 179/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 179: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 180/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 180: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 181/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 181: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 182/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 182: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 183/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 183: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 184/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 184: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 185/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 185: val_loss improved from 0.00697 to 0.00697, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch185_Loss0.0070\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 186/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 186: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 187/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 187: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 188/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 188: val_loss did not improve from 0.00697\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 189/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 189: val_loss improved from 0.00697 to 0.00695, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch189_Loss0.0069\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 190/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 190: val_loss improved from 0.00695 to 0.00693, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch190_Loss0.0069\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 191/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 191: val_loss improved from 0.00693 to 0.00693, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch191_Loss0.0069\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 192/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 192: val_loss did not improve from 0.00693\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 193/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 193: val_loss did not improve from 0.00693\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 194/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 194: val_loss improved from 0.00693 to 0.00693, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch194_Loss0.0069\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 195/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 195: val_loss did not improve from 0.00693\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 196/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 196: val_loss improved from 0.00693 to 0.00689, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch196_Loss0.0069\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 197/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 197: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 198/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 198: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 199/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 199: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 200/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 200: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 201/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 201: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 202/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 202: val_loss did not improve from 0.00689\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 203/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 203: val_loss improved from 0.00689 to 0.00686, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch203_Loss0.0069\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 204/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 204: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 205/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 205: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 206/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 206: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 207/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 207: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 208/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 208: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0072 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 209/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 209: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 210/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 210: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 211/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 211: val_loss improved from 0.00686 to 0.00686, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch211_Loss0.0069\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 212/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 212: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 213/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 213: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 214/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 214: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 215/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 215: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 216/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 216: val_loss did not improve from 0.00686\n",
            "891/891 [==============================] - 23s 26ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 217/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 217: val_loss improved from 0.00686 to 0.00684, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch217_Loss0.0068\n",
            "891/891 [==============================] - 24s 27ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 218/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 218: val_loss did not improve from 0.00684\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 219/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 219: val_loss did not improve from 0.00684\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 220/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 220: val_loss did not improve from 0.00684\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 221/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 221: val_loss did not improve from 0.00684\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 222/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 222: val_loss improved from 0.00684 to 0.00682, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch222_Loss0.0068\n",
            "891/891 [==============================] - 24s 26ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 223/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 223: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 224/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 224: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 225/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 225: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 226/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 226: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 227/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 227: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 228/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 228: val_loss did not improve from 0.00682\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 229/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 229: val_loss improved from 0.00682 to 0.00679, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch229_Loss0.0068\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 230/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 230: val_loss did not improve from 0.00679\n",
            "891/891 [==============================] - 19s 22ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 231/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 231: val_loss improved from 0.00679 to 0.00677, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch231_Loss0.0068\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 232/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 232: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 233/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 233: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 234/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 234: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 235/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 235: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 236/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 236: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 237/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 237: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 238/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 238: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 239/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 239: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 240/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 240: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0071 - val_loss: 0.0069 - lr: 0.0010\n",
            "Epoch 241/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 241: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 242/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 242: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 243/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 243: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0070 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 244/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 244: val_loss did not improve from 0.00677\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0070 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 245/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 245: val_loss improved from 0.00677 to 0.00676, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch245_Loss0.0068\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 246/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 246: val_loss did not improve from 0.00676\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 247/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 247: val_loss did not improve from 0.00676\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0071 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 248/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 248: val_loss did not improve from 0.00676\n",
            "891/891 [==============================] - 16s 18ms/step - loss: 0.0070 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 249/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 249: val_loss did not improve from 0.00676\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0070 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 250/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 250: val_loss improved from 0.00676 to 0.00674, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch250_Loss0.0067\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0070 - val_loss: 0.0067 - lr: 0.0010\n",
            "Epoch 251/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 251: val_loss did not improve from 0.00674\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0070 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 252/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 252: val_loss did not improve from 0.00674\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0070 - val_loss: 0.0068 - lr: 0.0010\n",
            "Epoch 253/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 253: val_loss improved from 0.00674 to 0.00660, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch253_Loss0.0066\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 254/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 254: val_loss improved from 0.00660 to 0.00658, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch254_Loss0.0066\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 255/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 255: val_loss improved from 0.00658 to 0.00657, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch255_Loss0.0066\n",
            "891/891 [==============================] - 25s 29ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 256/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 256: val_loss improved from 0.00657 to 0.00657, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch256_Loss0.0066\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 257/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 257: val_loss did not improve from 0.00657\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 258/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 258: val_loss improved from 0.00657 to 0.00656, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch258_Loss0.0066\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 259/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 259: val_loss improved from 0.00656 to 0.00656, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch259_Loss0.0066\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 260/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 260: val_loss did not improve from 0.00656\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 261/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 261: val_loss improved from 0.00656 to 0.00656, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch261_Loss0.0066\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0068 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 262/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 262: val_loss did not improve from 0.00656\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 263/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 263: val_loss did not improve from 0.00656\n",
            "891/891 [==============================] - 20s 22ms/step - loss: 0.0067 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 264/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 264: val_loss improved from 0.00656 to 0.00655, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch264_Loss0.0065\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 265/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 265: val_loss improved from 0.00655 to 0.00654, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch265_Loss0.0065\n",
            "891/891 [==============================] - 28s 32ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 266/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 266: val_loss did not improve from 0.00654\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 267/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 267: val_loss did not improve from 0.00654\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 268/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 268: val_loss improved from 0.00654 to 0.00654, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch268_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 269/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 269: val_loss did not improve from 0.00654\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 270/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 270: val_loss improved from 0.00654 to 0.00654, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch270_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 271/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 271: val_loss did not improve from 0.00654\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0066 - lr: 1.0000e-04\n",
            "Epoch 272/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 272: val_loss improved from 0.00654 to 0.00654, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch272_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 273/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 273: val_loss improved from 0.00654 to 0.00653, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch273_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 274/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 274: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 275/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 275: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 276/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 276: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 277/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 277: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 278/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 278: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 279/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 279: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 280/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 280: val_loss did not improve from 0.00653\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 281/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 281: val_loss improved from 0.00653 to 0.00653, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch281_Loss0.0065\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 282/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 282: val_loss improved from 0.00653 to 0.00653, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch282_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 283/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 283: val_loss improved from 0.00653 to 0.00652, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch283_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 284/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 284: val_loss did not improve from 0.00652\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 285/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 285: val_loss did not improve from 0.00652\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 286/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 286: val_loss did not improve from 0.00652\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 287/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 287: val_loss did not improve from 0.00652\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 288/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 288: val_loss improved from 0.00652 to 0.00652, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch288_Loss0.0065\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-04\n",
            "Epoch 289/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 289: val_loss improved from 0.00652 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch289_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 290/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 290: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 291/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 291: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch291_Loss0.0065\n",
            "891/891 [==============================] - 28s 31ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 292/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 292: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 293/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 293: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch293_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 294/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 294: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch294_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 295/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 295: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 296/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 296: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 297/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 297: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 298/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 298: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 299/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 299: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch299_Loss0.0065\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 300/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 300: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 301/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 301: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch301_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 302/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 302: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 303/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 303: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch303_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 304/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 304: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch304_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 305/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 305: val_loss did not improve from 0.00651\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 306/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 306: val_loss improved from 0.00651 to 0.00651, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch306_Loss0.0065\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 307/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 307: val_loss improved from 0.00651 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch307_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 308/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 308: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 309/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 309: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 310/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 310: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 311/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 311: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 312/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 312: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 313/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 313: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch313_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 314/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 314: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 315/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 315: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 20s 22ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 316/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 316: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 317/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 317: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch317_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 318/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 318: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 319/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 319: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 320/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 320: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 321/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 321: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 322/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 322: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 323/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 323: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 324/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 324: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 325/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 325: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch325_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 326/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 326: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 327/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 327: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 328/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 328: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 329/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 329: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 330/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 330: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 331/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 331: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 332/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 332: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch332_Loss0.0065\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 333/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 333: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 334/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 334: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 335/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 335: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 336/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 336: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch336_Loss0.0065\n",
            "891/891 [==============================] - 25s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 337/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 337: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 338/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 338: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 19ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 339/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 339: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch339_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 340/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 340: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 341/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 341: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 342/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 342: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 343/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 343: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 344/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 344: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 345/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 345: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 346/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 346: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 347/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 347: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 348/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 348: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch348_Loss0.0065\n",
            "891/891 [==============================] - 25s 28ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 349/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 349: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 350/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 350: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 351/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 351: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch351_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 352/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 352: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch352_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 353/400\n",
            "888/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 353: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 354/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 354: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 355/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 355: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 356/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 356: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 357/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 357: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch357_Loss0.0065\n",
            "891/891 [==============================] - 27s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 358/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 358: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 359/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 359: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch359_Loss0.0065\n",
            "891/891 [==============================] - 27s 31ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 360/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 360: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 361/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 361: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 362/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 362: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 363/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 363: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 364/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 364: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 365/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 365: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 366/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 366: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 367/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 367: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 368/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 368: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 369/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 369: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 20s 22ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 370/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 370: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 371/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 371: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 372/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 372: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 373/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 373: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch373_Loss0.0065\n",
            "891/891 [==============================] - 27s 31ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 374/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 374: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 375/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 375: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 376/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 376: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 377/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 377: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 378/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 378: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 379/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 379: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch379_Loss0.0065\n",
            "891/891 [==============================] - 26s 30ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 380/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 380: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 381/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 381: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 382/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 382: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 383/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 383: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch383_Loss0.0065\n",
            "891/891 [==============================] - 27s 31ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 384/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 384: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 385/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 385: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 17s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 386/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 386: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 387/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 387: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 388/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 388: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 389/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 389: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 390/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 390: val_loss improved from 0.00650 to 0.00650, saving model to Conv_GRU32_Dense_Gelu_Limit100_Stride10_NewSequences_Epoch390_Loss0.0065\n",
            "891/891 [==============================] - 26s 29ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 391/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 391: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 392/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 392: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 393/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 393: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 394/400\n",
            "890/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 394: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 395/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 395: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 396/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 396: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 21s 23ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 397/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 397: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 398/400\n",
            "889/891 [============================>.] - ETA: 0s - loss: 0.0067\n",
            "Epoch 398: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 399/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 399: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 18s 20ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n",
            "Epoch 400/400\n",
            "891/891 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 400: val_loss did not improve from 0.00650\n",
            "891/891 [==============================] - 19s 21ms/step - loss: 0.0067 - val_loss: 0.0065 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "filepath = 'Model_best_'\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val,y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=35, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=35, factor=0.1, min_lr=1e-5),\n",
        "        tfk.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fggFYnxki6fl"
      },
      "outputs": [],
      "source": [
        "# To load a pre-trained model instead of training from scratch:\n",
        "# model = tfk.models.load_model('Model_best_fancy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "hAJimV2TBPrz",
        "outputId": "b57de60e-d5c4-4699-cb51-509932feb9f5"
      },
      "outputs": [],
      "source": [
        "# best_epoch = np.argmin(history['val_loss'])\n",
        "# plt.figure(figsize=(17,4))\n",
        "# plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "# plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "# plt.title('Mean Squared Error')\n",
        "# plt.legend()\n",
        "# plt.grid(alpha=.3)\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(18,3))\n",
        "# plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "# plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "# plt.legend()\n",
        "# plt.grid(alpha=.3)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLUiF5Vrjymo"
      },
      "source": [
        "## 6. Evaluation on the test set\n",
        "\n",
        "We evaluate the best model on the test set (telescope = 18) using:\n",
        "- Mean Squared Error (MSE)\n",
        "- Mean Absolute Error (MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8HMNqyNjymy",
        "outputId": "d009c1e8-82bc-4495-ed39-ef162ab958d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions shape: (12664, 18, 1)\n",
            "Mean Squared Error: 0.007646671496331692\n",
            "Mean Absolute Error: 0.057307180017232895\n"
          ]
        }
      ],
      "source": [
        "# Predict the test set using the model\n",
        "predictions = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Print the shape of the predictions\n",
        "print(f\"Predictions shape: {predictions.shape}\")\n",
        "\n",
        "# Calculate and print Mean Squared Error (MSE)\n",
        "mean_squared_error = tfk.metrics.mean_squared_error(y_test.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
        "\n",
        "# Calculate and print Mean Absolute Error (MAE)\n",
        "mean_absolute_error = tfk.metrics.mean_absolute_error(y_test.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CGatDXaruLRz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
